{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           ID              SIZE      MODIFIED   \n",
      "llama3.1:8b    42182419e950    4.7 GB    6 days ago    \n",
      "llama3:8b      365c0bd3c000    4.7 GB    8 days ago    \n",
      "qwen2:7b       dd314f039b9d    4.4 GB    9 days ago    \n",
      "gemma2:9b      ff02c3702f32    5.4 GB    9 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = \"llama3:8b\"\n",
    "# llm = ChatOllama(model=local_model)\n",
    "llm = ChatOllama(model=local_model, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='llama3:8b')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r'F:\\AI\\Super AI SS4\\Level 3 - INTERN\\Jupyter Notebook\\Latest-Dataset-Model-Generate\\Random\\Latest-20-random.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>extractive</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>index_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>มิติหุ้น SKE คอนเฟิร์มรายได้ปี 62 เต...</td>\n",
       "      <td>\\t  บมจ.สากล เอนเนอยี หรือ SKE โดย นายจักรพงส์...</td>\n",
       "      <td>\\tนายจักรพงส์ สุเมธโชติเมธา กรรมการผู้จัดการให...</td>\n",
       "      <td>3017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ผลกระทบจากเชื้อไวรัสโคโรนา (โควิด-19...</td>\n",
       "      <td>ผลกระทบจากโควิด-19 ผลต่อกำไรของบริษั...</td>\n",
       "      <td>\\tนายมงคล พ่วงเภตรา ผู้ช่วยกรรมการผู้จัดการ ฝ่...</td>\n",
       "      <td>2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>องค์การส่งเสริมกิจการโคนมแห่งประเทศไ...</td>\n",
       "      <td>ดร.ณรงค์ฤทธิ์ วงศ์สุวรรณ ผู้อำนวยการ...</td>\n",
       "      <td>ดร.ณรงค์ฤทธิ์ วงศ์สุวรรณ ผู้อำนวยการ...</td>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>กระทรวงพลังงานใช้เวลาไป 1 ปี กับอีก ...</td>\n",
       "      <td>\\tกระทรวงพลังงานใช้เวลา 1 ปี 7 เดือน แก้ปมร...</td>\n",
       "      <td>\\tกระทรวงพลังงานใช้เวลา 1 ปี 7 เดือน แก้ปมร...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>นับเป็นอีกหนึ่งโครงการดีๆ ที่เปิดโอก...</td>\n",
       "      <td>\\t อีกหนึ่งโครงการดีๆ ที่เปิดโอกาสให้เด็ก ...</td>\n",
       "      <td>\\tโครงการประกวดศิลปกรรม ปตท. จากการสนับสนุนขอ...</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0            มิติหุ้น SKE คอนเฟิร์มรายได้ปี 62 เต...   \n",
       "1            ผลกระทบจากเชื้อไวรัสโคโรนา (โควิด-19...   \n",
       "2            องค์การส่งเสริมกิจการโคนมแห่งประเทศไ...   \n",
       "3            กระทรวงพลังงานใช้เวลาไป 1 ปี กับอีก ...   \n",
       "4            นับเป็นอีกหนึ่งโครงการดีๆ ที่เปิดโอก...   \n",
       "\n",
       "                                          extractive  \\\n",
       "0  \\t  บมจ.สากล เอนเนอยี หรือ SKE โดย นายจักรพงส์...   \n",
       "1            ผลกระทบจากโควิด-19 ผลต่อกำไรของบริษั...   \n",
       "2            ดร.ณรงค์ฤทธิ์ วงศ์สุวรรณ ผู้อำนวยการ...   \n",
       "3     \\tกระทรวงพลังงานใช้เวลา 1 ปี 7 เดือน แก้ปมร...   \n",
       "4      \\t อีกหนึ่งโครงการดีๆ ที่เปิดโอกาสให้เด็ก ...   \n",
       "\n",
       "                                         abstractive  index_original  \n",
       "0  \\tนายจักรพงส์ สุเมธโชติเมธา กรรมการผู้จัดการให...            3017  \n",
       "1  \\tนายมงคล พ่วงเภตรา ผู้ช่วยกรรมการผู้จัดการ ฝ่...            2844  \n",
       "2            ดร.ณรงค์ฤทธิ์ วงศ์สุวรรณ ผู้อำนวยการ...            2055  \n",
       "3     \\tกระทรวงพลังงานใช้เวลา 1 ปี 7 เดือน แก้ปมร...             199  \n",
       "4   \\tโครงการประกวดศิลปกรรม ปตท. จากการสนับสนุนขอ...             216  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_abstractive(text, llm):\n",
    "    system_template = \"\"\"You are an AI specialized in abstractive summarization for economic news articles.\"\"\"\n",
    "\n",
    "    prompt = \"\"\"Your task is to create an abstractive summary of the given news article. Follow these guidelines:\n",
    "    1. Summarize the content in Thai.\n",
    "    2. Use neutral, and clear language while maintaining a formal tone.\n",
    "    3. Use \\t at the beginning of each paragraph to create indentation.\n",
    "    4. Each paragraph should present a different point.\n",
    "    5. DO NOT leave blank lines between paragraphs. All paragraphs must be continuous with no blank lines.\n",
    "    6. Explain in detail the essence and main points of the article.\n",
    "    7. Ensure the summary is coherent and flows well as a standalone piece.\n",
    "    8. Preserve all important proper nouns such as names of people, companies, or organizations.\n",
    "    9. Organize the content logically, which may differ from the original article's structure if it improves clarity.\n",
    "    10. Synthesize information from different parts of the article when appropriate.\n",
    "    11. DO NOT include any examples or case studies in the summary.\n",
    "    \n",
    "    IMPORTANT:\n",
    "    - Please verify the accuracy of the information and present it in a neutral manner, without personal opinions or bias.\n",
    "    - Focus on creating a coherent, flowing summary that captures the main ideas without direct quoting.\n",
    "    - The summary has retained its original meaning and context.\n",
    "    \n",
    "    Article to summarize:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(prompt)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "\n",
    "    return llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_extractive(text, llm):\n",
    "    system_template = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "\n",
    "    prompt = \"\"\"Your task is to summarize the key content from the given news article. Follow these guidelines:\n",
    "    1. Summarize the content in Thai.\n",
    "    2. Use \\t at the beginning of each paragraph to create indentation.\n",
    "    3. DO NOT leave blank lines between paragraphs. All paragraphs must be continuous with no blank lines.\n",
    "    4. Focus on main points and important secondary points.\n",
    "    5. Provide explanations of the article’s key topics without going into too much detail.\n",
    "    6. Preserve all proper nouns such as names of people, companies, or organizations.\n",
    "    7. Use 2-3 key sentences from the original article for each point.\n",
    "    8. Maintain the original meaning and context.\n",
    "    9. Arrange the content in the same order as presented in the original article.\n",
    "    10. Reduce redundancy by combining similar points or information.\n",
    "    11. DO NOT include any examples in the summary.\n",
    "\n",
    "    IMPORTANT: \n",
    "    - DO NOT include any examples or case studies in the summary. Focus only on the main points and key information.\n",
    "\n",
    "    Article to summarize:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(prompt)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "\n",
    "    return llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           ID              SIZE      MODIFIED   \n",
      "llama3.1:8b    42182419e950    4.7 GB    6 days ago    \n",
      "llama3:8b      365c0bd3c000    4.7 GB    8 days ago    \n",
      "qwen2:7b       dd314f039b9d    4.4 GB    9 days ago    \n",
      "gemma2:9b      ff02c3702f32    5.4 GB    9 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return best-score, best-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  10%|█         | 1/10 [00:28<04:20, 28.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.83\n",
      "Epoch 1/10 | Current Score: 0.7650 | Best Score: 0.7650\n",
      "Current System Prompt: You are an AI specialized in extractive summarization for economic news articles....\n",
      "Current Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  20%|██        | 2/10 [00:59<03:59, 29.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.85\n",
      "Epoch 2/10 | Current Score: 0.8250 | Best Score: 0.8250\n",
      "Current System Prompt: Summarize the main points of an economic news article, focusing on key events, trends, and market im...\n",
      "Current Human Prompt: Summarize the main points from the following text: {text}...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  30%|███       | 3/10 [02:11<05:42, 48.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.73\n",
      "Epoch 3/10 | Current Score: 0.7300 | Best Score: 0.8250\n",
      "Current System Prompt: Summarize the key events, trends, and market impacts discussed in an economic news article, highligh...\n",
      "Current Human Prompt: Please summarize the key information and main ideas from the provided text: {text}...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  40%|████      | 4/10 [03:27<05:57, 59.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.85\n",
      "Epoch 4/10 | Current Score: 0.8500 | Best Score: 0.8500\n",
      "Current System Prompt: Summarize the main points, key trends, and significant market implications discussed in the news art...\n",
      "Current Human Prompt: Summarize the main points and key takeaways from the following text: {text}...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  50%|█████     | 5/10 [04:46<05:34, 66.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.81\n",
      "Epoch 5/10 | Current Score: 0.8650 | Best Score: 0.8650\n",
      "Current System Prompt: Summarize the news article, focusing on the most critical economic points, key trends, and significa...\n",
      "Current Human Prompt: What are the key points and main takeaways from the following text: {text}?...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  60%|██████    | 6/10 [06:28<05:14, 78.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.85\n",
      "Epoch 6/10 | Current Score: 0.8850 | Best Score: 0.8850\n",
      "Current System Prompt: Summarize the news article, highlighting the most critical economic points, their relevance, and imp...\n",
      "Current Human Prompt: Can you summarize the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  70%|███████   | 7/10 [07:14<03:24, 68.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.75\n",
      "Epoch 7/10 | Current Score: 0.7900 | Best Score: 0.8850\n",
      "Current System Prompt: Summarize the news article, focusing on the most critical economic points, their relevance to the br...\n",
      "Current Human Prompt: What are the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  80%|████████  | 8/10 [07:51<01:56, 58.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.85\n",
      "Epoch 8/10 | Current Score: 0.8500 | Best Score: 0.8850\n",
      "Current System Prompt: Summarize the news article, extracting the most critical economic information and highlighting key p...\n",
      "Current Human Prompt: Can you summarize the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  90%|█████████ | 9/10 [08:36<00:53, 53.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.92\n",
      "Epoch 9/10 | Current Score: 0.8700 | Best Score: 0.8850\n",
      "Current System Prompt: Extract the most critical economic information from the news article, focusing on key points and con...\n",
      "Current Human Prompt: What are the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n",
      "Extracted score: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts: 100%|██████████| 10/10 [09:09<00:00, 54.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted score: 0.81\n",
      "Epoch 10/10 | Current Score: 0.8300 | Best Score: 0.8850\n",
      "Current System Prompt: Extract the most critical economic information from the news article, focusing on key points and omi...\n",
      "Current Human Prompt: Can you summarize the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n",
      "\n",
      "Best System Prompt: Summarize the news article, highlighting the most critical economic points, their relevance, and importance in the broader economic context, and prioritize the most impactful information.\n",
      "\n",
      "Best Human Prompt: Can you summarize the main ideas and key points from the following text: {text}?\n",
      "\n",
      "Best Score: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "from textgrad.engine import get_engine\n",
    "\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "summary_model = \"llama3:8b\"  # Model for summarization (Ollama)\n",
    "llm_summarizer = ChatOllama(model=summary_model, use_gpu=True)\n",
    "\n",
    "# Set up Groq engine for textgrad\n",
    "engine = get_engine(\"groq-llama3-70b-8192\")\n",
    "tg.set_backward_engine(engine, override=True)\n",
    "\n",
    "def summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, text):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "    \n",
    "    response = llm_summarizer.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def evaluate_prompts(llm_summarizer, system_prompt, human_prompt, df):\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        summary = summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row['content'])\n",
    "        \n",
    "        eval_system_prompt = \"You are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Only output the score as a number, nothing else.\"\n",
    "        eval_human_prompt = f\"Generated: {summary}\\nReference: {row['label']}\\n\\nScore:\"\n",
    "        \n",
    "        eval_messages = [\n",
    "            {\"role\": \"system\", \"content\": eval_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": eval_human_prompt}\n",
    "        ]\n",
    "        \n",
    "        eval_response = llm_summarizer.invoke(eval_messages)\n",
    "        response_text = eval_response.content.strip()\n",
    "        \n",
    "        # Try to extract a float from the response\n",
    "        match = re.search(r'\\d+(\\.\\d+)?', response_text)\n",
    "        if match:\n",
    "            try:\n",
    "                score = float(match.group())\n",
    "                scores.append(score)\n",
    "                print(f\"Extracted score: {score:.4f}\")\n",
    "            except ValueError:\n",
    "                print(f\"Could not convert to float: {match.group()}\")\n",
    "                scores.append(0)\n",
    "        else:\n",
    "            print(f\"Could not extract score from: {response_text}\")\n",
    "            scores.append(0)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10):\n",
    "    system_prompt = Variable(initial_system_prompt, role_description=\"System prompt for summarization\")\n",
    "    human_prompt = Variable(initial_human_prompt, role_description=\"Human prompt for summarization\")\n",
    "    optimizer = TextualGradientDescent([system_prompt, human_prompt])\n",
    "    \n",
    "    best_score = 0\n",
    "    best_system_prompt = initial_system_prompt\n",
    "    best_human_prompt = initial_human_prompt\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Optimizing prompts\"):\n",
    "        current_score = evaluate_prompts(llm_summarizer, system_prompt.value, human_prompt.value, df)\n",
    "        \n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_system_prompt = system_prompt.value\n",
    "            best_human_prompt = human_prompt.value\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Current Score: {current_score:.4f} | Best Score: {best_score:.4f}\")\n",
    "        print(f\"Current System Prompt: {system_prompt.value[:100]}...\")\n",
    "        print(f\"Current Human Prompt: {human_prompt.value[:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Compute gradients and update prompts\n",
    "        loss = 1 - current_score  # We want to minimize this loss\n",
    "        loss_var = Variable(str(loss), role_description=\"Loss for optimization\")\n",
    "        loss_var.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return best_system_prompt, best_human_prompt, best_score\n",
    "\n",
    "def run_optimization(df):\n",
    "    initial_system_prompt = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "    initial_human_prompt = \"\"\"Your task is to summarize the key content from the given news article. Follow these guidelines:\n",
    "    1. Summarize the content in Thai.\n",
    "    2. Use \\t at the beginning of each paragraph to create indentation.\n",
    "    3. DO NOT leave blank lines between paragraphs. All paragraphs must be continuous with no blank lines.\n",
    "    4. Focus on main points and important secondary points.\n",
    "    5. Provide explanations of the article’s key topics without going into too much detail.\n",
    "    6. Preserve all proper nouns such as names of people, companies, or organizations.\n",
    "    7. Use 2-3 key sentences from the original article for each point.\n",
    "    8. Maintain the original meaning and context.\n",
    "    9. Arrange the content in the same order as presented in the original article.\n",
    "    10. Reduce redundancy by combining similar points or information.\n",
    "    11. DO NOT include any examples in the summary.\n",
    "\n",
    "    IMPORTANT: \n",
    "    - DO NOT include any examples or case studies in the summary. Focus only on the main points and key information.\n",
    "\n",
    "    Article to summarize:\n",
    "    {text}\"\"\"\n",
    "    \n",
    "    best_system_prompt, best_human_prompt, best_score = optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10)\n",
    "    \n",
    "    print(\"\\nBest System Prompt:\", best_system_prompt)\n",
    "    print(\"\\nBest Human Prompt:\", best_human_prompt)\n",
    "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
    "\n",
    "file_path = r'F:\\AI\\Super AI SS4\\Level 3 - INTERN\\Dataset\\ThEconSum\\AIFORTHAI-TextSummarizationCorpus\\lstsumv1.test.jsonl'\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    return pd.read_json(file_path, lines=True)\n",
    "\n",
    "test = read_jsonl_file(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "test = test.drop(columns=['author', 'datePublish'])\n",
    "\n",
    "# Randomly sample 10-20 examples from the test DataFrame\n",
    "n_samples = 10  # Change to 20 if you want 20 samples\n",
    "sampled_test = test.sample(n=n_samples, random_state=42)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_optimization(sampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  10%|█         | 1/10 [00:23<03:35, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Current Score: 0.8417 | Best Score: 0.8417\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  20%|██        | 2/10 [00:52<03:31, 26.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Current Score: 0.8500 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  30%|███       | 3/10 [01:25<03:28, 29.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Current Score: 0.7650 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  40%|████      | 4/10 [01:57<03:03, 30.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Current Score: 0.7900 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  50%|█████     | 5/10 [02:27<02:31, 30.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Current Score: 0.7750 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  60%|██████    | 6/10 [03:01<02:06, 31.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Current Score: 0.7750 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  70%|███████   | 7/10 [03:28<01:29, 29.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Current Score: 0.8500 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  80%|████████  | 8/10 [04:03<01:03, 31.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Current Score: 0.7750 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  90%|█████████ | 9/10 [04:31<00:30, 30.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Current Score: 0.8000 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts: 100%|██████████| 10/10 [05:03<00:00, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Current Score: 0.8817 | Best Score: 0.8817\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01)...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Best System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01)\n",
      "\n",
      "Best Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main points. Summarize the following text: {text} (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01) (Adjusted by 0.01)\n",
      "\n",
      "Best Score: 0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.engine import get_engine\n",
    "\n",
    "# Set Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Initialize models\n",
    "summary_model = \"llama3:8b\"  # Model for summarization (Ollama)\n",
    "llm_summarizer = ChatOllama(model=summary_model, use_gpu=True)\n",
    "\n",
    "# Set up Groq engine for textgrad\n",
    "engine = get_engine(\"groq-llama3-70b-8192\")\n",
    "tg.set_backward_engine(engine, override=True)\n",
    "\n",
    "# Function to generate summary with given prompts\n",
    "def summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, text):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "    \n",
    "    response = llm_summarizer.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def evaluate_prompts(llm_summarizer, system_prompt, human_prompt, df):\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        summary = summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row['content'])\n",
    "        \n",
    "        eval_system_prompt = \"You are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Only output the score as a number, nothing else.\"\n",
    "        eval_human_prompt = f\"Generated: {summary}\\nReference: {row['label']}\\n\\nScore:\"\n",
    "        \n",
    "        eval_messages = [\n",
    "            {\"role\": \"system\", \"content\": eval_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": eval_human_prompt}\n",
    "        ]\n",
    "        \n",
    "        eval_response = llm_summarizer.invoke(eval_messages)\n",
    "        response_text = eval_response.content.strip()\n",
    "        \n",
    "        match = re.search(r'\\d+(\\.\\d+)?', response_text)\n",
    "        if match:\n",
    "            try:\n",
    "                score = float(match.group())\n",
    "                scores.append(score)\n",
    "            except ValueError:\n",
    "                print(f\"Could not convert to float: {match.group()}\")\n",
    "                scores.append(0)\n",
    "        else:\n",
    "            print(f\"Could not extract score from: {response_text}\")\n",
    "            scores.append(0)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def compute_gradient(prompt, loss):\n",
    "    # Placeholder for gradient computation logic\n",
    "    # You need to implement the logic for calculating how prompt affects the loss\n",
    "    return np.random.normal(size=len(prompt))  # Dummy gradient\n",
    "\n",
    "def update_prompt(prompt, gradient, learning_rate):\n",
    "    # Simple update logic based on gradient\n",
    "    new_prompt = prompt  # Replace with actual prompt updating logic\n",
    "    return new_prompt + f\" (Adjusted by {learning_rate})\"\n",
    "\n",
    "def optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10, learning_rate=0.01):\n",
    "    system_prompt = Variable(initial_system_prompt, role_description=\"System prompt for summarization\")\n",
    "    human_prompt = Variable(initial_human_prompt, role_description=\"Human prompt for summarization\")\n",
    "    \n",
    "    best_score = 0\n",
    "    best_system_prompt = initial_system_prompt\n",
    "    best_human_prompt = initial_human_prompt\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Optimizing prompts\"):\n",
    "        current_score = evaluate_prompts(llm_summarizer, system_prompt.value, human_prompt.value, df)\n",
    "        \n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_system_prompt = system_prompt.value\n",
    "            best_human_prompt = human_prompt.value\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Current Score: {current_score:.4f} | Best Score: {best_score:.4f}\")\n",
    "\n",
    "        # Compute loss\n",
    "        loss = 1 - current_score  # We want to minimize this loss\n",
    "        loss_var = Variable(str(loss), role_description=\"Loss for optimization\")\n",
    "        \n",
    "        # Calculate gradients for system and human prompts\n",
    "        system_gradient = compute_gradient(system_prompt.value, loss_var)\n",
    "        human_gradient = compute_gradient(human_prompt.value, loss_var)\n",
    "        \n",
    "        # Update prompts using gradients\n",
    "        system_prompt.value = update_prompt(system_prompt.value, system_gradient, learning_rate)\n",
    "        human_prompt.value = update_prompt(human_prompt.value, human_gradient, learning_rate)\n",
    "        \n",
    "        # Print prompt changes\n",
    "        print(f\"Updated System Prompt: {system_prompt.value[:100]}...\")\n",
    "        print(f\"Updated Human Prompt: {human_prompt.value[:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return best_system_prompt, best_human_prompt, best_score\n",
    "\n",
    "def run_optimization(df):\n",
    "    initial_system_prompt = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "    initial_human_prompt = \"\"\"Your task is to summarize the key content from the given news article in Thai, focusing on the main points. Summarize the following text: {text}\"\"\"\n",
    "    \n",
    "    best_system_prompt, best_human_prompt, best_score = optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10, learning_rate=0.01)\n",
    "    \n",
    "    print(\"\\nBest System Prompt:\", best_system_prompt)\n",
    "    print(\"\\nBest Human Prompt:\", best_human_prompt)\n",
    "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
    "\n",
    "# Sample dataframe for testing\n",
    "def create_sample_dataframe():\n",
    "    data = {\n",
    "        'content': [\n",
    "            \"เศรษฐกิจไทยในไตรมาสที่ 2 ปี 2566 เติบโต 1.8% เทียบกับช่วงเดียวกันของปีก่อน โดยได้แรงหนุนจากการบริโภคภาคเอกชนและการส่งออกบริการที่ฟื้นตัว แม้การส่งออกสินค้าจะหดตัว\",\n",
    "            \"ธนาคารแห่งประเทศไทยคงอัตราดอกเบี้ยนโยบายที่ 2.25% ในการประชุมเมื่อวันที่ 27 กันยายน 2566 โดยให้เหตุผลว่าเศรษฐกิจไทยมีแนวโน้มฟื้นตัวต่อเนื่อง แม้จะเผชิญความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ],\n",
    "        'label': [\n",
    "            \"เศรษฐกิจไทย Q2/2566 โต 1.8% จากการบริโภคเอกชนและการส่งออกบริการฟื้นตัว\",\n",
    "            \"ธปท. คงดอกเบี้ย 2.25% เห็นเศรษฐกิจฟื้นต่อเนื่องแม้มีความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_sample_dataframe()\n",
    "    run_optimization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  10%|█         | 1/10 [00:33<05:01, 33.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Current Score: 0.8500 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  20%|██        | 2/10 [01:03<04:12, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Current Score: 0.8350 | Best Score: 0.8500\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  30%|███       | 3/10 [01:42<04:03, 34.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Current Score: 0.8625 | Best Score: 0.8625\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  40%|████      | 4/10 [02:15<03:25, 34.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Current Score: 0.7650 | Best Score: 0.8625\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  50%|█████     | 5/10 [02:48<02:47, 33.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Current Score: 0.7500 | Best Score: 0.8625\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  60%|██████    | 6/10 [03:23<02:16, 34.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Current Score: 0.7650 | Best Score: 0.8625\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  70%|███████   | 7/10 [03:53<01:38, 32.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Current Score: 0.8785 | Best Score: 0.8785\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  80%|████████  | 8/10 [04:27<01:06, 33.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Current Score: 0.7750 | Best Score: 0.8785\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  90%|█████████ | 9/10 [05:07<00:35, 35.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Current Score: 0.8535 | Best Score: 0.8785\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts: 100%|██████████| 10/10 [05:39<00:00, 33.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Current Score: 0.7950 | Best Score: 0.8785\n",
      "Updated System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.010...\n",
      "Updated Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Best System Prompt: You are an AI specialized in extractive summarization for economic news articles. (Adjusted by 0.0100) (Adjusted by 0.0100) (Adjusted by 0.0100) (Adjusted by 0.0100) (Adjusted by 0.0100) (Adjusted by 0.0100)\n",
      "\n",
      "Best Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main points. Summarize the following text: {text} (Adjusted by 0.0100) (Adjusted by 0.0100) (Adjusted by 0.0100) (Adjusted by 0.0100) (Adjusted by 0.0100) (Adjusted by 0.0100)\n",
      "\n",
      "Best Score: 0.8785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.engine import get_engine\n",
    "\n",
    "# Set Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"your_groq_api_key_here\"\n",
    "\n",
    "# Initialize models\n",
    "summary_model = \"llama3:8b\"\n",
    "llm_summarizer = ChatOllama(model=summary_model, use_gpu=True)\n",
    "\n",
    "# Set up Groq engine for textgrad\n",
    "engine = get_engine(\"groq-llama3-70b-8192\")\n",
    "tg.set_backward_engine(engine, override=True)\n",
    "\n",
    "def summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, text):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "    \n",
    "    response = llm_summarizer.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def evaluate_prompts(llm_summarizer, system_prompt, human_prompt, df):\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        summary = summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row['content'])\n",
    "        \n",
    "        eval_system_prompt = \"You are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Only output the score as a number, nothing else.\"\n",
    "        eval_human_prompt = f\"Generated: {summary}\\nReference: {row['label']}\\n\\nScore:\"\n",
    "        \n",
    "        eval_messages = [\n",
    "            {\"role\": \"system\", \"content\": eval_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": eval_human_prompt}\n",
    "        ]\n",
    "        \n",
    "        eval_response = llm_summarizer.invoke(eval_messages)\n",
    "        response_text = eval_response.content.strip()\n",
    "        \n",
    "        match = re.search(r'\\d+(\\.\\d+)?', response_text)\n",
    "        if match:\n",
    "            try:\n",
    "                score = float(match.group())\n",
    "                scores.append(score)\n",
    "            except ValueError:\n",
    "                scores.append(0)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def compute_gradient(prompt, loss):\n",
    "    # Example: compute gradient based on loss\n",
    "    # In practice, implement logic to reflect how prompt changes affect loss\n",
    "    # This is a placeholder for illustration purposes\n",
    "    return np.random.normal(0, 0.1, size=len(prompt))\n",
    "\n",
    "def update_prompt(prompt, gradient, learning_rate):\n",
    "    # Here, we create an adjustment string based on the gradient\n",
    "    adjustment = f\" (Adjusted by {learning_rate:.4f})\"\n",
    "    new_prompt = prompt + adjustment\n",
    "    return new_prompt\n",
    "\n",
    "def optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10, learning_rate=0.01):\n",
    "    system_prompt = Variable(initial_system_prompt, role_description=\"System prompt for summarization\")\n",
    "    human_prompt = Variable(initial_human_prompt, role_description=\"Human prompt for summarization\")\n",
    "    \n",
    "    best_score = 0\n",
    "    best_system_prompt = initial_system_prompt\n",
    "    best_human_prompt = initial_human_prompt\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Optimizing prompts\"):\n",
    "        current_score = evaluate_prompts(llm_summarizer, system_prompt.value, human_prompt.value, df)\n",
    "        \n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_system_prompt = system_prompt.value\n",
    "            best_human_prompt = human_prompt.value\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Current Score: {current_score:.4f} | Best Score: {best_score:.4f}\")\n",
    "\n",
    "        # Compute loss\n",
    "        loss = 1 - current_score\n",
    "        loss_var = Variable(str(loss), role_description=\"Loss for optimization\")\n",
    "        \n",
    "        # Calculate gradients for system and human prompts\n",
    "        system_gradient = compute_gradient(system_prompt.value, loss_var)\n",
    "        human_gradient = compute_gradient(human_prompt.value, loss_var)\n",
    "        \n",
    "        # Update prompts using gradients\n",
    "        system_prompt.value = update_prompt(system_prompt.value, system_gradient, learning_rate)\n",
    "        human_prompt.value = update_prompt(human_prompt.value, human_gradient, learning_rate)\n",
    "        \n",
    "        # Print prompt changes\n",
    "        print(f\"Updated System Prompt: {system_prompt.value[:100]}...\")\n",
    "        print(f\"Updated Human Prompt: {human_prompt.value[:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return best_system_prompt, best_human_prompt, best_score\n",
    "\n",
    "def run_optimization(df):\n",
    "    initial_system_prompt = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "    initial_human_prompt = \"\"\"Your task is to summarize the key content from the given news article in Thai, focusing on the main points. Summarize the following text: {text}\"\"\"\n",
    "    \n",
    "    best_system_prompt, best_human_prompt, best_score = optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10, learning_rate=0.01)\n",
    "    \n",
    "    print(\"\\nBest System Prompt:\", best_system_prompt)\n",
    "    print(\"\\nBest Human Prompt:\", best_human_prompt)\n",
    "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
    "\n",
    "# Sample dataframe for testing\n",
    "def create_sample_dataframe():\n",
    "    data = {\n",
    "        'content': [\n",
    "            \"เศรษฐกิจไทยในไตรมาสที่ 2 ปี 2566 เติบโต 1.8% เทียบกับช่วงเดียวกันของปีก่อน โดยได้แรงหนุนจากการบริโภคภาคเอกชนและการส่งออกบริการที่ฟื้นตัว แม้การส่งออกสินค้าจะหดตัว\",\n",
    "            \"ธนาคารแห่งประเทศไทยคงอัตราดอกเบี้ยนโยบายที่ 2.25% ในการประชุมเมื่อวันที่ 27 กันยายน 2566 โดยให้เหตุผลว่าเศรษฐกิจไทยมีแนวโน้มฟื้นตัวต่อเนื่อง แม้จะเผชิญความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ],\n",
    "        'label': [\n",
    "            \"เศรษฐกิจไทย Q2/2566 โต 1.8% จากการบริโภคเอกชนและการส่งออกบริการฟื้นตัว\",\n",
    "            \"ธปท. คงดอกเบี้ย 2.25% เห็นเศรษฐกิจฟื้นต่อเนื่องแม้มีความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_sample_dataframe()\n",
    "    run_optimization(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  10%|█         | 1/10 [00:46<07:00, 46.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Current Score: 0.8300 | Best Score: 0.8300\n",
      "Current System Prompt: You are an AI specialized in extractive summarization for economic news articles....\n",
      "Current Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  20%|██        | 2/10 [01:23<05:29, 41.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Current Score: 0.8250 | Best Score: 0.8300\n",
      "Current System Prompt: Summarize the main points of an economic news article, focusing on key events, trends, and market im...\n",
      "Current Human Prompt: Summarize the main points from the following text: {text}...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  30%|███       | 3/10 [02:46<07:00, 60.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Current Score: 0.9250 | Best Score: 0.9250\n",
      "Current System Prompt: Summarize the key events, trends, and market impacts discussed in an economic news article, highligh...\n",
      "Current Human Prompt: Please summarize the key information and main ideas from the provided text: {text}...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  40%|████      | 4/10 [04:23<07:28, 74.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Current Score: 0.8700 | Best Score: 0.9250\n",
      "Current System Prompt: Summarize the main points, key trends, and significant market implications discussed in the news art...\n",
      "Current Human Prompt: Summarize the main points and key takeaways from the following text: {text}...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  50%|█████     | 5/10 [05:54<06:41, 80.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Current Score: 0.8400 | Best Score: 0.9250\n",
      "Current System Prompt: Summarize the news article, focusing on the most critical economic points, key trends, and significa...\n",
      "Current Human Prompt: What are the key points and main takeaways from the following text: {text}?...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  60%|██████    | 6/10 [07:27<05:38, 84.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Current Score: 0.7750 | Best Score: 0.9250\n",
      "Current System Prompt: Summarize the news article, highlighting the most critical economic points, their relevance, and imp...\n",
      "Current Human Prompt: Can you summarize the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  70%|███████   | 7/10 [08:36<03:58, 79.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Current Score: 0.8300 | Best Score: 0.9250\n",
      "Current System Prompt: Summarize the news article, focusing on the most critical economic points, their relevance to the br...\n",
      "Current Human Prompt: What are the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  80%|████████  | 8/10 [09:24<02:18, 69.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Current Score: 0.7750 | Best Score: 0.9250\n",
      "Current System Prompt: Summarize the news article, extracting the most critical economic information and highlighting key p...\n",
      "Current Human Prompt: Can you summarize the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  90%|█████████ | 9/10 [10:05<01:00, 60.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Current Score: 0.7900 | Best Score: 0.9250\n",
      "Current System Prompt: Extract the most critical economic information from the news article, focusing on key points and con...\n",
      "Current Human Prompt: What are the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts: 100%|██████████| 10/10 [10:43<00:00, 64.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Current Score: 0.8600 | Best Score: 0.9250\n",
      "Current System Prompt: Extract the most critical economic information from the news article, focusing on key points and omi...\n",
      "Current Human Prompt: Can you summarize the main ideas and key points from the following text: {text}?...\n",
      "--------------------------------------------------\n",
      "\n",
      "Best System Prompt: Summarize the key events, trends, and market impacts discussed in an economic news article, highlighting their significance and relevance to the economy.\n",
      "\n",
      "Best Human Prompt: Please summarize the key information and main ideas from the provided text: {text}\n",
      "\n",
      "Best Score: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "from textgrad.engine import get_engine\n",
    "\n",
    "# Set Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Initialize models\n",
    "summary_model = \"llama3:8b\"  # Model for summarization (Ollama)\n",
    "llm_summarizer = ChatOllama(model=summary_model, use_gpu=True)\n",
    "\n",
    "# Set up Groq engine for textgrad\n",
    "engine = get_engine(\"groq-llama3-70b-8192\")\n",
    "tg.set_backward_engine(engine, override=True)\n",
    "\n",
    "# Function to generate summary with given prompts\n",
    "def summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, text):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "    \n",
    "    response = llm_summarizer.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def evaluate_prompts(llm_summarizer, system_prompt, human_prompt, df):\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        summary = summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row['content'])\n",
    "        \n",
    "        eval_system_prompt = \"You are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Only output the score as a number, nothing else.\"\n",
    "        eval_human_prompt = f\"Generated: {summary}\\nReference: {row['label']}\\n\\nScore:\"\n",
    "        \n",
    "        eval_messages = [\n",
    "            {\"role\": \"system\", \"content\": eval_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": eval_human_prompt}\n",
    "        ]\n",
    "        \n",
    "        eval_response = llm_summarizer.invoke(eval_messages)\n",
    "        response_text = eval_response.content.strip()\n",
    "        \n",
    "        match = re.search(r'\\d+(\\.\\d+)?', response_text)\n",
    "        if match:\n",
    "            try:\n",
    "                score = float(match.group())\n",
    "                scores.append(score)\n",
    "                # Comment out or remove the line below to suppress score printing\n",
    "                # print(f\"Extracted score: {score:.4f}\")\n",
    "            except ValueError:\n",
    "                print(f\"Could not convert to float: {match.group()}\")\n",
    "                scores.append(0)\n",
    "        else:\n",
    "            print(f\"Could not extract score from: {response_text}\")\n",
    "            scores.append(0)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10):\n",
    "    system_prompt = Variable(initial_system_prompt, role_description=\"System prompt for summarization\")\n",
    "    human_prompt = Variable(initial_human_prompt, role_description=\"Human prompt for summarization\")\n",
    "    optimizer = TextualGradientDescent([system_prompt, human_prompt])\n",
    "    \n",
    "    best_score = 0\n",
    "    best_system_prompt = initial_system_prompt\n",
    "    best_human_prompt = initial_human_prompt\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Optimizing prompts\"):\n",
    "        current_score = evaluate_prompts(llm_summarizer, system_prompt.value, human_prompt.value, df)\n",
    "        \n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_system_prompt = system_prompt.value\n",
    "            best_human_prompt = human_prompt.value\n",
    "        \n",
    "        # แสดงเฉพาะข้อมูลที่ต้องการ\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Current Score: {current_score:.4f} | Best Score: {best_score:.4f}\")\n",
    "        print(f\"Current System Prompt: {system_prompt.value[:100]}...\")\n",
    "        print(f\"Current Human Prompt: {human_prompt.value[:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Compute gradients and update prompts\n",
    "        loss = 1 - current_score  # We want to minimize this loss\n",
    "        loss_var = Variable(str(loss), role_description=\"Loss for optimization\")\n",
    "        loss_var.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return best_system_prompt, best_human_prompt, best_score\n",
    "\n",
    "# ฟังก์ชัน run_optimization เพื่อรันการปรับแต่ง prompt\n",
    "def run_optimization(df):\n",
    "    initial_system_prompt = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "    initial_human_prompt = \"\"\"Your task is to summarize the key content from the given news article in Thai, focusing on the main points. Summarize the following text: {text}\"\"\"\n",
    "    \n",
    "    best_system_prompt, best_human_prompt, best_score = optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10)\n",
    "    \n",
    "    print(\"\\nBest System Prompt:\", best_system_prompt)\n",
    "    print(\"\\nBest Human Prompt:\", best_human_prompt)\n",
    "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
    "\n",
    "# Sample dataframe for testing\n",
    "def create_sample_dataframe():\n",
    "    data = {\n",
    "        'content': [\n",
    "            \"เศรษฐกิจไทยในไตรมาสที่ 2 ปี 2566 เติบโต 1.8% เทียบกับช่วงเดียวกันของปีก่อน โดยได้แรงหนุนจากการบริโภคภาคเอกชนและการส่งออกบริการที่ฟื้นตัว แม้การส่งออกสินค้าจะหดตัว\",\n",
    "            \"ธนาคารแห่งประเทศไทยคงอัตราดอกเบี้ยนโยบายที่ 2.25% ในการประชุมเมื่อวันที่ 27 กันยายน 2566 โดยให้เหตุผลว่าเศรษฐกิจไทยมีแนวโน้มฟื้นตัวต่อเนื่อง แม้จะเผชิญความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ],\n",
    "        'label': [\n",
    "            \"เศรษฐกิจไทย Q2/2566 โต 1.8% จากการบริโภคเอกชนและการส่งออกบริการฟื้นตัว\",\n",
    "            \"ธปท. คงดอกเบี้ย 2.25% เห็นเศรษฐกิจฟื้นต่อเนื่องแม้มีความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_sample_dataframe()\n",
    "    run_optimization(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Current Score: 0.7500 | Best Score: 0.7500\n",
      "Current System Prompt: You are an AI specialized in extractive summarization for economic news articles....\n",
      "Current Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09350\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\textgrad\\optimizer\\optimizer.py:178: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  new_text = self.engine(prompt_update_parameter, system_prompt=self.optimizer_system_prompt)\n",
      "Optimizing prompts:  10%|█         | 1/10 [00:50<07:30, 50.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Current Score: 0.5600 | Best Score: 0.7500\n",
      "Current System Prompt: You are an AI designed to analyze economic news articles and generate concise summaries of the key p...\n",
      "Current Human Prompt: Summarize the provided text by identifying the main ideas and key points, focusing on brevity and cl...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  20%|██        | 2/10 [01:30<05:55, 44.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Current Score: 0.5600 | Best Score: 0.7500\n",
      "Current System Prompt: You are an AI designed to provide concise and accurate summaries of economic news articles, extracti...\n",
      "Current Human Prompt: Summarize the provided text by condensing its key points into a concise summary that retains its ess...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  30%|███       | 3/10 [02:10<04:57, 42.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Current Score: 0.7600 | Best Score: 0.7600\n",
      "Current System Prompt: You are an AI designed to distill complex information into concise summaries, presenting key points ...\n",
      "Current Human Prompt: Condense the provided text into a summary that captures its main points, key ideas, and essential in...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  40%|████      | 4/10 [02:50<04:08, 41.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Current Score: 0.6400 | Best Score: 0.7600\n",
      "Current System Prompt: You are an AI designed to provide concise overviews of complex information, highlighting the most es...\n",
      "Current Human Prompt: Condense the provided text into a concise summary that accurately captures its main points, while re...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  50%|█████     | 5/10 [03:33<03:29, 41.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Current Score: 0.5850 | Best Score: 0.7600\n",
      "Current System Prompt: You are an AI designed to distill complex information into bite-sized summaries that capture the ess...\n",
      "Current Human Prompt: Provide a concise summary that distills the main points from the original text into 2-3 key takeaway...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  60%|██████    | 6/10 [04:17<02:50, 42.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Current Score: 0.6550 | Best Score: 0.7600\n",
      "Current System Prompt: You are an AI designed to quickly summarize complex information into key points, making it easier fo...\n",
      "Current Human Prompt: Provide a concise summary that captures the essence of the original text by extracting 2-3 key point...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  70%|███████   | 7/10 [04:57<02:05, 41.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Current Score: 0.6900 | Best Score: 0.7600\n",
      "Current System Prompt: You're an AI that simplifies complex info, helping users stay informed on diverse topics by providin...\n",
      "Current Human Prompt: Provide a concise summary that distills the main points of the text, highlighting key information an...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  80%|████████  | 8/10 [05:38<01:23, 41.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Current Score: 0.4050 | Best Score: 0.7600\n",
      "Current System Prompt: We help users quickly grasp complex information by providing clear, concise summaries across various...\n",
      "Current Human Prompt: Provide a concise summary that distills the main points of the provided text, while preserving its o...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  90%|█████████ | 9/10 [06:20<00:41, 41.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Current Score: 0.4050 | Best Score: 0.7600\n",
      "Current System Prompt: We help users quickly understand complex topics with personalized summaries....\n",
      "Current Human Prompt: Condense the content into a clear and concise summary that captures its key ideas, emotional resonan...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts: 100%|██████████| 10/10 [07:01<00:00, 42.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best System Prompt: You are an AI designed to distill complex information into concise summaries, presenting key points in a clear and easy-to-understand format for users.\n",
      "\n",
      "Best Human Prompt: Condense the provided text into a summary that captures its main points, key ideas, and essential information, ensuring the summary is accurate and retains the original's significance.\n",
      "\n",
      "Best Score: 0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "from textgrad.engine import get_engine\n",
    "\n",
    "# Initialize models\n",
    "summary_model = \"llama3:8b\"  # Model for summarization (Ollama)\n",
    "llm_summarizer = ChatOllama(model=summary_model, use_gpu=True)\n",
    "\n",
    "# Set up Ollama engine for textgrad\n",
    "ollama_engine = Ollama(model=\"llama3.1:8b\")\n",
    "tg.set_backward_engine(ollama_engine, override=True)\n",
    "\n",
    "# Function to generate summary with given prompts\n",
    "def summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, text):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "    \n",
    "    response = llm_summarizer.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def evaluate_prompts(llm_summarizer, system_prompt, human_prompt, df):\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        summary = summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row['content'])\n",
    "        \n",
    "        eval_system_prompt = \"You are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Only output the score as a number, nothing else.\"\n",
    "        eval_human_prompt = f\"Generated: {summary}\\nReference: {row['label']}\\n\\nScore:\"\n",
    "        \n",
    "        eval_messages = [\n",
    "            {\"role\": \"system\", \"content\": eval_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": eval_human_prompt}\n",
    "        ]\n",
    "        \n",
    "        eval_response = llm_summarizer.invoke(eval_messages)\n",
    "        response_text = eval_response.content.strip()\n",
    "        \n",
    "        match = re.search(r'\\d+(\\.\\d+)?', response_text)\n",
    "        if match:\n",
    "            try:\n",
    "                score = float(match.group())\n",
    "                scores.append(score)\n",
    "            except ValueError:\n",
    "                print(f\"Could not convert to float: {match.group()}\")\n",
    "                scores.append(0)\n",
    "        else:\n",
    "            print(f\"Could not extract score from: {response_text}\")\n",
    "            scores.append(0)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10):\n",
    "    system_prompt = Variable(initial_system_prompt, role_description=\"System prompt for summarization\")\n",
    "    human_prompt = Variable(initial_human_prompt, role_description=\"Human prompt for summarization\")\n",
    "    optimizer = TextualGradientDescent([system_prompt, human_prompt])\n",
    "    \n",
    "    best_score = 0\n",
    "    best_system_prompt = initial_system_prompt\n",
    "    best_human_prompt = initial_human_prompt\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Optimizing prompts\"):\n",
    "        current_score = evaluate_prompts(llm_summarizer, system_prompt.value, human_prompt.value, df)\n",
    "        \n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_system_prompt = system_prompt.value\n",
    "            best_human_prompt = human_prompt.value\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Current Score: {current_score:.4f} | Best Score: {best_score:.4f}\")\n",
    "        print(f\"Current System Prompt: {system_prompt.value[:100]}...\")\n",
    "        print(f\"Current Human Prompt: {human_prompt.value[:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Compute gradients and update prompts\n",
    "        loss = 1 - current_score  # We want to minimize this loss\n",
    "        loss_var = Variable(str(loss), role_description=\"Loss for optimization\")\n",
    "        loss_var.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return best_system_prompt, best_human_prompt, best_score\n",
    "\n",
    "# Function to run optimization\n",
    "def run_optimization(df):\n",
    "    initial_system_prompt = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "    initial_human_prompt = \"\"\"Your task is to summarize the key content from the given news article in Thai, focusing on the main points. Summarize the following text: {text}\"\"\"\n",
    "    \n",
    "    best_system_prompt, best_human_prompt, best_score = optimize_prompts(llm_summarizer, initial_system_prompt, initial_human_prompt, df, epochs=10)\n",
    "    \n",
    "    print(\"\\nBest System Prompt:\", best_system_prompt)\n",
    "    print(\"\\nBest Human Prompt:\", best_human_prompt)\n",
    "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
    "\n",
    "# Sample dataframe for testing\n",
    "def create_sample_dataframe():\n",
    "    data = {\n",
    "        'content': [\n",
    "            \"เศรษฐกิจไทยในไตรมาสที่ 2 ปี 2566 เติบโต 1.8% เทียบกับช่วงเดียวกันของปีก่อน โดยได้แรงหนุนจากการบริโภคภาคเอกชนและการส่งออกบริการที่ฟื้นตัว แม้การส่งออกสินค้าจะหดตัว\",\n",
    "            \"ธนาคารแห่งประเทศไทยคงอัตราดอกเบี้ยนโยบายที่ 2.25% ในการประชุมเมื่อวันที่ 27 กันยายน 2566 โดยให้เหตุผลว่าเศรษฐกิจไทยมีแนวโน้มฟื้นตัวต่อเนื่อง แม้จะเผชิญความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ],\n",
    "        'label': [\n",
    "            \"เศรษฐกิจไทย Q2/2566 โต 1.8% จากการบริโภคเอกชนและการส่งออกบริการฟื้นตัว\",\n",
    "            \"ธปท. คงดอกเบี้ย 2.25% เห็นเศรษฐกิจฟื้นต่อเนื่องแม้มีความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_sample_dataframe()\n",
    "    run_optimization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Current Score: 0.9200 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI specialized in extractive summarization for economic news articles....\n",
      "Current Human Prompt: Your task is to summarize the key content from the given news article in Thai, focusing on the main ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  10%|█         | 1/10 [01:17<11:34, 77.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Current Score: 0.2750 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI model designed to read and summarize economic news articles by extracting key points, ...\n",
      "Current Human Prompt: Your task is to condense the main ideas from the provided text into a concise summary, highlighting ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  20%|██        | 2/10 [02:20<09:10, 68.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Current Score: 0.0100 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI model designed to read and summarize key information from various sources, providing a...\n",
      "Current Human Prompt: Your task is to distill the essential information from the provided summary, focusing on the key tak...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  30%|███       | 3/10 [03:30<08:05, 69.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Current Score: 0.2000 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI model designed to read and summarize a wide range of content, from news articles and r...\n",
      "Current Human Prompt: Your task is to distill the essential information from a given text or summary, focusing on key poin...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  40%|████      | 4/10 [04:40<06:58, 69.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Current Score: 0.0850 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI model designed to provide concise and accurate summaries of complex information, stayi...\n",
      "Current Human Prompt: Your task is to condense a lengthy text into a brief summary, focusing on the most important points ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  50%|█████     | 5/10 [05:42<05:35, 67.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Current Score: 0.2650 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI model designed to provide concise and actionable information, distilling complex ideas...\n",
      "Current Human Prompt: Your task is to reduce a lengthy text into a concise summary, highlighting the most crucial informat...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  60%|██████    | 6/10 [06:46<04:23, 65.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Current Score: 0.1550 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI model designed to distill complex information into concise summaries that pinpoint key...\n",
      "Current Human Prompt: Your task is to condense a lengthy text into a concise summary that captures the main points and key...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  70%|███████   | 7/10 [07:43<03:09, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Current Score: 0.2500 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI model designed to extract key points from lengthy texts, condensing complex informatio...\n",
      "Current Human Prompt: Your task is to shorten a lengthy text into a brief summary that highlights the primary points and e...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  80%|████████  | 8/10 [09:02<02:16, 68.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Current Score: 0.6850 | Best Score: 0.9200\n",
      "Current System Prompt: You are an AI model designed to condense complex information into concise summaries, distilling esse...\n",
      "Current Human Prompt: Summarize a lengthy text into 1-2 concise paragraphs that capture its main points and key takeaways,...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  90%|█████████ | 9/10 [10:33<01:15, 75.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Current Score: 0.9650 | Best Score: 0.9650\n",
      "Current System Prompt: You are an AI model designed to craft concise summaries of complex information, boiling down lengthy...\n",
      "Current Human Prompt: Summarize a lengthy text into 1-2 concise paragraphs that capture the main idea, key points, and ess...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts: 100%|██████████| 10/10 [12:38<00:00, 75.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best System Prompt: You are an AI model designed to craft concise summaries of complex information, boiling down lengthy content into easily digestible, essential points that highlight key takeaways.\n",
      "\n",
      "Best Human Prompt: Summarize a lengthy text into 1-2 concise paragraphs that capture the main idea, key points, and essential information, while avoiding unnecessary details and focusing on clarity and readability. Be sure to highlight any statistics, quotes, or crucial data mentioned in the original text.\n",
      "\n",
      "Best Score: 0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "from textgrad.engine import get_engine\n",
    "\n",
    "# Initialize models\n",
    "summary_model = \"llama3:8b\"  # Model for summarization (Ollama)\n",
    "llm_summarizer = ChatOllama(model=summary_model, use_gpu=True)\n",
    "\n",
    "# Set up Ollama engine for textgrad (evaluation and prompt optimization)\n",
    "ollama_engine = Ollama(model=\"llama3.1:8b\")\n",
    "tg.set_backward_engine(ollama_engine, override=True)\n",
    "\n",
    "# Function to generate summary with given prompts (using llm_summarizer)\n",
    "def summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, text):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "    \n",
    "    response = llm_summarizer.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "# Function to evaluate summaries using Ollama engine\n",
    "def evaluate_summary(ollama_engine, generated_summary, reference_summary):\n",
    "    eval_prompt = f\"\"\"You are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Only output the score as a number, nothing else.\n",
    "\n",
    "Generated: {generated_summary}\n",
    "Reference: {reference_summary}\n",
    "\n",
    "Score:\"\"\"\n",
    "    \n",
    "    response = ollama_engine(eval_prompt)\n",
    "    match = re.search(r'\\d+(\\.\\d+)?', response)\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group())\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert to float: {match.group()}\")\n",
    "            return 0\n",
    "    else:\n",
    "        print(f\"Could not extract score from: {response}\")\n",
    "        return 0\n",
    "\n",
    "def evaluate_prompts(llm_summarizer, ollama_engine, system_prompt, human_prompt, df):\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        summary = summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row['content'])\n",
    "        score = evaluate_summary(ollama_engine, summary, row['label'])\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_prompts(llm_summarizer, ollama_engine, initial_system_prompt, initial_human_prompt, df, epochs=10):\n",
    "    system_prompt = Variable(initial_system_prompt, role_description=\"System prompt for summarization\")\n",
    "    human_prompt = Variable(initial_human_prompt, role_description=\"Human prompt for summarization\")\n",
    "    optimizer = TextualGradientDescent([system_prompt, human_prompt])\n",
    "    \n",
    "    best_score = 0\n",
    "    best_system_prompt = initial_system_prompt\n",
    "    best_human_prompt = initial_human_prompt\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Optimizing prompts\"):\n",
    "        try:\n",
    "            current_score = evaluate_prompts(llm_summarizer, ollama_engine, system_prompt.value, human_prompt.value, df)\n",
    "        \n",
    "            if current_score > best_score:\n",
    "                best_score = current_score\n",
    "                best_system_prompt = system_prompt.value\n",
    "                best_human_prompt = human_prompt.value\n",
    "        \n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Current Score: {current_score:.4f} | Best Score: {best_score:.4f}\")\n",
    "            print(f\"Current System Prompt: {system_prompt.value[:100]}...\")\n",
    "            print(f\"Current Human Prompt: {human_prompt.value[:100]}...\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "            # Compute gradients and update prompts using Ollama engine\n",
    "            loss = 1 - current_score  # We want to minimize this loss\n",
    "            loss_var = Variable(str(loss), role_description=\"Loss for optimization\")\n",
    "            loss_var.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError occurred: {e}\")\n",
    "            print(f\"Current system prompt: {system_prompt.value}\")\n",
    "            print(f\"Current human prompt: {human_prompt.value}\")\n",
    "    \n",
    "    return best_system_prompt, best_human_prompt, best_score\n",
    "\n",
    "# Function to run optimization\n",
    "def run_optimization(df):\n",
    "    initial_system_prompt = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "    initial_human_prompt = \"\"\"Your task is to summarize the key content from the given news article in Thai, focusing on the main points. Summarize the following text: {text}\"\"\"\n",
    "    \n",
    "    best_system_prompt, best_human_prompt, best_score = optimize_prompts(llm_summarizer, ollama_engine, initial_system_prompt, initial_human_prompt, df, epochs=10)\n",
    "    \n",
    "    print(\"\\nBest System Prompt:\", best_system_prompt)\n",
    "    print(\"\\nBest Human Prompt:\", best_human_prompt)\n",
    "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
    "\n",
    "# Sample dataframe for testing\n",
    "def create_sample_dataframe():\n",
    "    data = {\n",
    "        'content': [\n",
    "            \"เศรษฐกิจไทยในไตรมาสที่ 2 ปี 2566 เติบโต 1.8% เทียบกับช่วงเดียวกันของปีก่อน โดยได้แรงหนุนจากการบริโภคภาคเอกชนและการส่งออกบริการที่ฟื้นตัว แม้การส่งออกสินค้าจะหดตัว\",\n",
    "            \"ธนาคารแห่งประเทศไทยคงอัตราดอกเบี้ยนโยบายที่ 2.25% ในการประชุมเมื่อวันที่ 27 กันยายน 2566 โดยให้เหตุผลว่าเศรษฐกิจไทยมีแนวโน้มฟื้นตัวต่อเนื่อง แม้จะเผชิญความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ],\n",
    "        'label': [\n",
    "            \"เศรษฐกิจไทย Q2/2566 โต 1.8% จากการบริโภคเอกชนและการส่งออกบริการฟื้นตัว\",\n",
    "            \"ธปท. คงดอกเบี้ย 2.25% เห็นเศรษฐกิจฟื้นต่อเนื่องแม้มีความเสี่ยงจากเศรษฐกิจโลก\"\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_sample_dataframe()\n",
    "    run_optimization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           ID              SIZE      MODIFIED   \n",
      "llama3.1:8b    42182419e950    4.7 GB    6 days ago    \n",
      "llama3:8b      365c0bd3c000    4.7 GB    8 days ago    \n",
      "qwen2:7b       dd314f039b9d    4.4 GB    9 days ago    \n",
      "gemma2:9b      ff02c3702f32    5.4 GB    9 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation explanation: **Score:** 0.85 (very good)\n",
      "\n",
      "The generated summary is well-structured and covers the main points of the reference summary, including:\n",
      "\n",
      "1. The total fund-raising in the Thai stock market for 2020 (approximately 500 billion THB).\n",
      "2. The strength of listed companies in Thailand, which were able to overcome the COVID-19 pandemic.\n",
      "3. The launch of Initial Public Offering (IPO) by several companies, including SCGP and KEX.\n",
      "4. The performance of SCGP, which saw a significant increase in stock price.\n",
      "\n",
      "However, there are some minor differences between the generated summary and the reference summary:\n",
      "\n",
      "1. The number of IPOs mentioned is different (22 vs 25).\n",
      "2. The market capitalization of SCGP at IPO is not explicitly stated in the generated summary.\n",
      "3. Some details about other companies, such as PTT and KEX, are missing or differ slightly.\n",
      "\n",
      "Overall, the generated summary provides a good overview of the key points, but could be improved with more specific details and accurate numbers.\n",
      "Evaluation explanation: The generated summary is a good attempt at summarizing the article, but it falls short in terms of content coverage and clarity. Here's why:\n",
      "\n",
      "* Content coverage: The generated summary mentions some of the key points, such as PTT's new business direction, success with OR and Amazon Cafe, and expansion into healthcare. However, it omits important details about the establishment of Innobik (Asia) and its potential synergy with petrochemical businesses.\n",
      "* Clarity: The language used in the generated summary is concise but not always clear. Some sentences are a bit choppy or ambiguous, making it difficult to understand the main points.\n",
      "* Conciseness: While the generated summary is brief, it could be even more concise by combining similar ideas and eliminating redundant phrases.\n",
      "\n",
      "Overall, I would give the generated summary a score of 0.6 out of 1. It's not bad, but it could be improved with more attention to content coverage, clarity, and conciseness.\n",
      "Evaluation explanation: **Score: 0.7**\n",
      "\n",
      "The generated summary covers some of the key points from the original article, including:\n",
      "\n",
      "* The Thai economy's recovery, particularly in export, tourism, and investment\n",
      "* The Eastern Economic Corridor (EEC) as a highlight of the country's economic growth\n",
      "* Plans to promote SMEs and support entrepreneurship\n",
      "* Recent events, such as the selection process for a new CEO of Thai Airways, and the establishment of a new hotel brand by PTT\n",
      "\n",
      "However, there are some omissions and inaccuracies in the generated summary:\n",
      "\n",
      "* The EEC is not mentioned as an initiative that will \"drew more foreign investment\" (as stated in the generated summary), but rather as a key area for economic growth.\n",
      "* The reference to SMEs support is not explicitly mentioned in the original article, although it is implied.\n",
      "* Some events and announcements are missing from the generated summary, such as the SET Youth Music Competition and the Thailand Local Tourism Design contest.\n",
      "\n",
      "Overall, while the generated summary provides some useful information, it lacks depth and accuracy compared to the reference summary.\n",
      "Evaluation explanation: Here's a brief explanation of my reasoning:\n",
      "\n",
      "**Content Coverage**: Both the generated and reference summaries cover the main points about PRM's business growth, investment plans, and expected profits. However, the reference summary provides more detailed information on the company's financial performance, specific business segments, and investment plans.\n",
      "\n",
      "**Conciseness**: The generated summary is slightly longer than the reference summary but still concise enough to convey the essential points.\n",
      "\n",
      "**Clarity**: Both summaries are easy to understand, but the reference summary is more coherent in its structure and sentence flow.\n",
      "\n",
      "Given these factors, I'd rate the generated summary a score of **0.85/1**. While it effectively covers the main points, it could benefit from a bit more detail and clarity to match the quality of the reference summary.\n",
      "Evaluation explanation: Here's the comparison between the generated summary and the reference summary:\n",
      "\n",
      "**Content coverage**: The generated summary covers some of the key points from the reference summary, such as GPSC's collaboration with 24 M Technologies, the development of a pilot plant for battery production, and the benefits of 24 M's battery technology. However, it lacks details about specific products (e.g., LFP batteries) and quotes from executives.\n",
      "\n",
      "**Conciseness**: The generated summary is concise and to the point, but it omits some important information that is present in the reference summary.\n",
      "\n",
      "**Clarity**: The language used in the generated summary is clear, but it may not be as precise or detailed as the reference summary.\n",
      "\n",
      "Overall score: 0.7\n",
      "\n",
      "The generated summary scores 70% because it provides a good overview of GPSC's collaboration with 24 M Technologies and the benefits of their battery technology. However, it lacks some crucial details and specific examples that are present in the reference summary. With more precise language and additional details, the generated summary could score even higher!\n",
      "Evaluation explanation: The generated summary scores 0.8 out of 1.\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* Content coverage: The summary covers the main points, including Prinya's background, the vision for water management, key initiatives, and investment plans. However, it misses some details from the reference summary, such as specific goals and timelines.\n",
      "* Conciseness: The generated summary is concise and to the point, but it could be more compact while still retaining essential information.\n",
      "* Clarity: The language used in the generated summary is clear, but it may not fully capture the nuances of the original text. Some technical terms, such as \"G้าวสู่ Digital MWA\" and \"e-Service,\" are explained, which is helpful.\n",
      "\n",
      "To improve the score, the generated summary could provide more specific details, incorporate more direct quotes from Prinya (if available), and further clarify complex technical concepts.\n",
      "Evaluation explanation: **Score: 0.85**\n",
      "\n",
      "The generated summary is highly accurate, covering all the essential points from the reference summary. The content coverage is excellent, with no major omissions or distortions. The conciseness of the generated summary is also good, conveying the main ideas in a clear and concise manner.\n",
      "\n",
      "However, there are some minor differences in wording and structure between the two summaries, which slightly affects the clarity and flow of the generated summary. Nevertheless, the overall quality of the generated summary is very high, with a clear and accurate representation of the key points from the reference summary.\n",
      "Evaluation explanation: The generated summary and the reference summary are both discussing a request from the Chonburi Real Estate Association to the government to develop land in the eastern economic corridor (EEC) for the development of areas around high-speed train stations, including a new city in Sriracha-Chonburi. \n",
      "\n",
      "The content coverage is mostly the same, with both summaries mentioning the association's request for 1,000 rai of state-owned land within a 50-60 km radius from the Sriracha high-speed train station to be developed for transportation-oriented development (TOD) and new city projects. They also both mention that the current price of land in Chonburi is too high, and that more supply is needed to reduce prices.\n",
      "\n",
      "However, the conciseness and clarity of the generated summary are not as good as the reference summary. The generated summary has some awkward phrasing and sentence structures, while the reference summary is more concise and clear in its language. Additionally, the generated summary misses out on some details that are present in the reference summary, such as the association's suggestion to use a land management approach similar to other countries, and the recent meeting between the real estate group and PTT to discuss a plan for developing areas around train stations.\n",
      "\n",
      "Score: 0.7\n",
      "Evaluation explanation: After comparing the generated summary with the reference summary, I would give a score of 0.7 out of 1.\n",
      "\n",
      "The generated summary covers most of the key points from the original text, including:\n",
      "\n",
      "* Improved sales in Q2/2562 due to high season demand for electricity\n",
      "* GPSC's four power generation projects online, including one in Laos and one in Thailand\n",
      "* Recognition of GLOW profits for a full quarter\n",
      "* Plans to increase the debt-to-equity ratio to 7-8 times from the current 20 times\n",
      "\n",
      "However, there are some minor issues with the generated summary:\n",
      "\n",
      "* The reference summary provides more specific details about GPSC's four power generation projects and their locations.\n",
      "* The generated summary is slightly redundant, as it repeats a sentence about GPSC's debt-to-equity ratio without adding new information.\n",
      "* Some of the sentences in the generated summary seem to be word-for-word copies from the original text, which can make the summary feel less concise and clear.\n",
      "\n",
      "Overall, while the generated summary captures most of the essential points from the reference summary, it could benefit from a bit more detail and clarity to reach a perfect score. Hence, the score is 0.7 out of 1.\n",
      "Evaluation explanation: Here's the comparison between the generated summary and the reference summary:\n",
      "\n",
      "**Content coverage**: The generated summary covers most of the key points mentioned in the reference summary, but with some minor omissions. It mentions the three possible outcomes from the OPEC meeting, the potential impact on oil prices, and the recommendations for PTT and PTTEP stocks. However, it doesn't explicitly mention the expected growth rate of PTTEP's profits.\n",
      "\n",
      "**Conciseness**: The generated summary is more concise than the reference summary, but this comes at the cost of some detail. Some key numbers, such as the 1.7 million barrel/day reduction in oil production, are missing.\n",
      "\n",
      "**Clarity**: The generated summary is clear and easy to understand, but it's not as precise as the reference summary. For example, it mentions that PTTEP has a \"strong foundation\" for growth, but doesn't explain what this means.\n",
      "\n",
      "Considering these factors, I would give the generated summary a score of 0.8 out of 1. It's a good summary, but could be improved by including more details and being more precise with numbers.\n",
      "Evaluation explanation: The generated summary is incomplete and lacks important details compared to the reference summary. Here's a brief explanation of my reasoning:\n",
      "\n",
      "* Content coverage: The generated summary only mentions that KIAT won the contract for transporting LNG from PTT, but it doesn't specify the duration (5 years) or the total value of the contract (100 million baht). In contrast, the reference summary provides more detailed information about the contract and its significance.\n",
      "* Conciseness: The generated summary is concise, but at the cost of omitting crucial details. The reference summary provides a clearer understanding of the context and implications of KIAT's winning the contract.\n",
      "* Clarity: Both summaries are written in clear Thai language, but the generated summary lacks precision and specificity.\n",
      "\n",
      "Score: 0.6/1\n",
      "\n",
      "The generated summary receives a score of 0.6 because it covers some essential points, such as KIAT's victory in the bidding process and the potential for increased revenue. However, the omission of key details and lack of conciseness make it incomplete and less informative compared to the reference summary.\n",
      "Evaluation explanation: Here's the comparison between the generated summary and the reference summary:\n",
      "\n",
      "**Content Coverage:** The generated summary covers about 70-80% of the content in the reference summary. It mentions the low success rate of startups in Thailand, the challenges faced by Claim Di and Giztix, and the importance of fundraising and partnership. However, it doesn't mention some specific details such as the percentage of startups that fail to reach series A funding (90%), or the experience of Fastwork.\n",
      "\n",
      "**Conciseness:** The generated summary is concise, but slightly less so than the reference summary. It takes about 100-120 words to convey the main points, whereas the reference summary can be read in around 150-160 words.\n",
      "\n",
      "**Clarity:** The clarity of both summaries is good, with no major issues regarding readability or understanding.\n",
      "\n",
      "Overall, I would give the generated summary a score of **0.8** (out of 1) based on its content coverage, conciseness, and clarity. While it doesn't perfectly capture all the details from the reference summary, it conveys the main points effectively and is written in a clear manner.\n",
      "Evaluation explanation: The generated summary has a score of 0.8 out of 1.\n",
      "\n",
      "Strengths:\n",
      "\n",
      "* The summary covers the main points of ESG bonds, including their purpose and types (Green, Social, and Sustainability bonds).\n",
      "* It mentions several examples of companies that have issued ESG bonds, such as Chanel, Burberry, Saudi Electricity, and Daimler AG.\n",
      "* The summary provides some context about the growth of ESG bond issuance in Thailand.\n",
      "\n",
      "Weaknesses:\n",
      "\n",
      "* The generated summary is not entirely concise, with some sentences being a bit long and wordy.\n",
      "* It lacks clarity in some places, particularly when describing the specific projects that companies have funded through their ESG bonds (e.g., \"การสร้างอาคารสีเขียว หรือพัฒนาเทคโนโลยีสะอาด\").\n",
      "* The summary does not provide as much depth or detail as the reference summary, which is more informative and provides specific examples and context.\n",
      "* There are some minor errors in translation, such as the use of \"sustainability-linked bond\" instead of the correct term \"green bond\".\n",
      "\n",
      "Overall, while the generated summary is a good start, it could benefit from further refinement to improve its conciseness, clarity, and accuracy.\n",
      "Evaluation explanation: Here's the evaluation of the generated summary compared to the reference summary:\n",
      "\n",
      "**Content Coverage**: The generated summary covers 80% of the content in the reference summary, missing some specific details about the impact on Thai energy companies.\n",
      "\n",
      "**Conciseness**: The generated summary is concise and to the point, but could be more detailed. It's worth a score of 0.8 out of 1.\n",
      "\n",
      "**Clarity**: The language used in the generated summary is clear and easy to understand, making it accessible to a wider audience.\n",
      "\n",
      "Overall Score: **0.85**\n",
      "\n",
      "The generated summary provides a good overview of the situation, but some minor details are missing or simplified. The clarity and conciseness make up for this, however. Overall, I'd give it a score of 0.85 out of 1, indicating that it's very close to being an excellent summary, with just a few minor issues holding it back from perfection.\n",
      "Evaluation explanation: After comparing the generated summary with the reference summary, I would give it a score of 0.8.\n",
      "\n",
      "The generated summary accurately covers the main points, including:\n",
      "\n",
      "* ACAP's plan to issue its third bond in 2017 (3-5 October)\n",
      "* The bond's details (not exceeding 500 million THB, 2-year maturity, and 6% interest rate)\n",
      "* ACAP's intention to use the proceeds from the bond issuance to expand its loan portfolio\n",
      "* The current size of ACAP's loan portfolio (around 5 billion THB) and its target (6 billion THB this year)\n",
      "* ACAP's plan to expand its loan portfolio to 20 billion THB in the next 5 years\n",
      "\n",
      "However, there are some minor differences:\n",
      "\n",
      "* The generated summary does not mention the credit rating from TRIS Rating (BBStable), which is mentioned in the reference summary.\n",
      "* The language and sentence structure in the generated summary are simpler than those in the reference summary.\n",
      "\n",
      "Overall, the generated summary provides a clear and concise overview of ACAP's bond issuance plan and its loan expansion strategy, but lacks some details present in the reference summary. Hence, the score of 0.8.\n",
      "Evaluation explanation: The generated summary covers the main points of the situation, including the significant decline in the stock market index (17.26%) and the concerns surrounding COVID-19. However, it lacks specific details about the impact on various sectors or industries.\n",
      "\n",
      "In contrast, the reference summary provides a more comprehensive overview of the market's performance, highlighting the 28.54% decline in the index over the past year, which is the lowest in eight years. The reference summary also delves deeper into the concerns among investors and the subsequent buying by company executives to shore up their companies' foundations.\n",
      "\n",
      "Score: 0.8\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* Content coverage: 0.7 (The generated summary covers the main points, but lacks specific details about the impact on various sectors or industries.)\n",
      "* Conciseness: 0.9 (Both summaries are concise and to the point, but the reference summary provides more context and supporting information.)\n",
      "* Clarity: 0.8 (Both summaries are clear, but the reference summary uses more precise language and avoids ambiguity.)\n",
      "Evaluation explanation: The generated summary is quite comprehensive, covering the main points of the reference summary. However, there are some minor differences in wording and content coverage.\n",
      "\n",
      "Content Coverage: 0.8/1\n",
      "The generated summary covers around 80% of the key points mentioned in the reference summary. It includes the increase in food delivery boxes due to COVID-19, the rise in plastic waste, GC's goal to reduce single-use plastics, and their initiatives such as \"ส่งพลาสติกกลับบ้าน\" (Sending Plastic Back Home) and \"อัพไซคลิงอัพสไตล์ลิ่ง\" (Upcycling Upstyling).\n",
      "\n",
      "Conciseness: 0.9/1\n",
      "The generated summary is concise, with around 10-15% less content than the reference summary.\n",
      "\n",
      "Clarity: 0.8/1\n",
      "The generated summary is clear and easy to understand, but it lacks some of the specific details and examples mentioned in the reference summary.\n",
      "\n",
      "Overall Score: 0.85/1\n",
      "\n",
      "Reasoning:\n",
      "While the generated summary covers most of the key points, there are some minor differences in wording and content coverage. The reference summary provides more specific examples and details, making it a more comprehensive read. However, the generated summary is still quite clear and concise, making it a good starting point for readers who want to understand GC's initiatives on plastic waste management.\n",
      "Evaluation explanation: The generated summary and the reference summary share similar content, but there are some differences in terms of detail and clarity.\n",
      "\n",
      "The generated summary focuses more on the specific changes to the gas import policy, mentioning that PTT is currently the sole importer of LNG. It also mentions that a committee has reworked the process for establishing an LNG division, with a new allocation ratio of 70% long-term contracts and 30% short-term contracts.\n",
      "\n",
      "The reference summary provides more context and background information on the energy policy and the goals of opening up the gas market to private players. It explains why the old import ratio was deemed unfair and how the new ratio aims to achieve balance in three areas: price, security, and competition.\n",
      "\n",
      "In terms of content coverage, the generated summary scores 0.7 out of 1, as it does not mention the full context of the energy policy changes or the importance of having both long-term and short-term contracts for LNG imports. The reference summary scores 1 out of 1 in this regard.\n",
      "\n",
      "However, the generated summary excels in conciseness and clarity, presenting a clear and concise summary of the key points (0.9 out of 1).\n",
      "\n",
      "Overall, I would give the generated summary a score of 0.8 out of 1, as it effectively conveys the main points but lacks some context and detail compared to the reference summary.\n",
      "Evaluation explanation: **Score:** 0.8\n",
      "\n",
      "The generated summary is a good representation of the original article, but it lacks some details and clarity compared to the reference summary.\n",
      "\n",
      "Strengths:\n",
      "\n",
      "* The generated summary covers the main points, such as PTT's monitoring of the drought situation, preparation for water-saving measures, and proposal to open up a PPP project to produce fresh water from seawater.\n",
      "* It also mentions PTT's plans to adjust gas imports and explore alternative markets.\n",
      "\n",
      "Weaknesses:\n",
      "\n",
      "* Some details are missing or not clearly explained, such as the specific regions affected by the drought and the locations of the proposed PPP projects.\n",
      "* The generated summary lacks quotes from the CEO, which provide additional context and insights in the reference summary.\n",
      "* There are some minor errors in translation, but they do not significantly affect the overall meaning.\n",
      "\n",
      "Overall, while the generated summary is a good start, it could benefit from more thorough analysis and attention to detail to match the quality of the reference summary.\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I will compare it with the reference summary.\n",
      "\n",
      "The generated summary covers most of the key points from the reference summary, including:\n",
      "\n",
      "* The signing of a 2-year contract between SCN and PTT for maintenance and operation of NGV stations\n",
      "* SCN's role as a service provider for over 150 NGV stations across Bangkok and surrounding areas\n",
      "* SCN's expertise in NGV systems and its experience dating back to the early days of Thailand's adoption of NGV\n",
      "\n",
      "However, there are some minor discrepancies and omissions:\n",
      "\n",
      "* The generated summary does not mention Dr. Rithi Gijpich as the president of SCN, nor does it provide a specific date for the signing of the contract.\n",
      "* It also does not include information about SCN's market share or its role in developing the NGV industry.\n",
      "\n",
      "Despite these minor issues, I would rate the generated summary as 0.85/1. The summary is concise and clear, covering most of the essential points from the reference summary. However, it could benefit from more precise details and a stronger connection to the original text.\n",
      "\n",
      "Score: 0.85\n",
      "Epoch 1/4 | Current Score: 13.9755 | Best Score: 13.9755\n",
      "Current System Prompt: You are an AI specialized in extractive summarization for economic news articles....\n",
      "Current Human Prompt: Your task is to summarize the key content from the given news article. Follow these guidelines:\n",
      "    ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  25%|██▌       | 1/4 [45:51<2:17:33, 2751.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation explanation: The generated summary is a brief statement that responds to the prompt, but it fails to capture the essence of the reference summary. The content coverage is extremely low, as it only mentions \"adding a phrase\" without any context or relevance to the topic discussed in the reference summary.\n",
      "\n",
      "The generated summary also lacks clarity and conciseness, making it difficult to understand what it's trying to convey. It appears to be unrelated to the topic of fundraising in the Thai stock market, which is the main focus of the reference summary.\n",
      "\n",
      "In contrast, the reference summary provides a clear and concise overview of the topic, highlighting key statistics, quotes from an official, and specific examples of companies that have gone public or are planning to do so. It also touches on the impact of COVID-19 on the stock market and the growing trend of online trading.\n",
      "\n",
      "Based on this analysis, I would give the generated summary a score of 0 out of 1, indicating that it is not relevant or accurate in capturing the essence of the topic.\n",
      "Evaluation explanation: The generated summary does not provide a clear understanding of the article's content. It seems to be focused on providing advice for generating summaries, rather than summarizing the actual article.\n",
      "\n",
      "The reference summary, however, provides a comprehensive overview of PTT's efforts to shift towards a new business model (New S-Curve) focusing on life sciences and healthcare. It mentions specific initiatives such as partnering with the Thai Food and Drug Administration to create the first cancer treatment factory in Thailand, and establishing Innobik (Asia) with a 2 billion baht investment.\n",
      "\n",
      "Comparing the two summaries, I would give the generated summary a score of **0** out of 1, as it does not accurately reflect the content of the article. The reference summary scores around **0.8**, as it effectively conveys the main points of PTT's business transformation efforts.\n",
      "Evaluation explanation: Unfortunately, the generated summary does not align with the reference summary at all. The content is completely different, and there is no overlap in terms of ideas or information. This suggests that the generated summary fails to cover any relevant points from the original text.\n",
      "\n",
      "The reason for this discrepancy lies in the fact that the generated summary appears to be a response to a question about summarizing financial news articles, rather than an actual attempt to summarize the provided text. The tone and language used are also unrelated to the content of the reference summary.\n",
      "\n",
      "Therefore, I would assign a score of **0** out of 1, as the generated summary does not demonstrate any quality in terms of content coverage, conciseness, or clarity.\n",
      "Evaluation explanation: Here's the comparison:\n",
      "\n",
      "**Generated Summary:** I understand! Adding a phrase like \"Highlight the key takeaways\" or \"Summarize in 50-60 words\" to my prompt will help me deliver the most concise and useful summary for financial news articles.\n",
      "\n",
      "This generated summary is completely unrelated to the article content, which means it doesn't cover any of the main points. Therefore, I'll give a score of **0**. There's no comparison to be made with the reference summary since they're not related at all.\n",
      "\n",
      "Let me know if you'd like to generate another summary for the provided article!\n",
      "Evaluation explanation: The generated summary has no relation to the reference summary. The reference summary discusses a company called GPSC investing in another company, 24 M Technologies, which develops a new battery technology. In contrast, the generated summary only mentions adding a phrase to highlight key takeaways from financial news articles.\n",
      "\n",
      "Reasoning: The content coverage is zero, conciseness is irrelevant since there's no actual summary provided, and clarity is not an issue in this case as there are no key points being summarized. Therefore, the score would be 0.\n",
      "Evaluation explanation: **Score: 0.4**\n",
      "\n",
      "The generated summary is very short, but unfortunately, it doesn't capture the essence of the article. The reference summary provides a clear overview of the new director's vision for the waterworks department, including key initiatives such as digitalization, expanding coverage, and improving services.\n",
      "\n",
      "In contrast, the generated summary consists only of two sentences that seem unrelated to the main topic. It mentions adding phrases to provide direction on output length and focus, but this is not a summary itself. The content coverage is very poor, with no mention of the key takeaways or important points from the article. Clarity and conciseness are also lacking.\n",
      "\n",
      "To improve the score, I would expect a generated summary that condenses the main ideas and initiatives discussed in the reference summary, perhaps within 50-60 words as suggested by the original prompt.\n",
      "Evaluation explanation: **Score: 0.2**\n",
      "\n",
      "The generated summary is extremely short (16 words) compared to the reference summary (134 words), which makes it difficult to assess its content coverage, conciseness, and clarity. The generated summary only mentions that the AI system can be given clear direction with a prompt like \"Highlight the key takeaways\", but it does not relate to the actual topic of the article about PTT's plans for commercial LNG exports.\n",
      "\n",
      "In contrast, the reference summary provides detailed information on the topic, including PTT's plans to start commercial LNG exports in Q2 2021, the impact of COVID-19 on energy demand and prices, and the expected decline in domestic gas consumption.\n",
      "Evaluation explanation: The generated summary is a response to a prompt, but it does not seem to be related to the reference article. The content is about summarization skills, while the reference article appears to be about real estate development in Chonburi province.\n",
      "\n",
      "However, if we were to compare the generated summary with a hypothetical reference summary (which would also be unrelated to the actual reference article), I could evaluate its quality.\n",
      "\n",
      "The generated summary has 4 sentences, and it seems concise. However, it does not provide any relevant information or insights, which is a major drawback for a summary. The tone is casual and conversational, which may not be suitable for a formal summary.\n",
      "\n",
      "Score: 0 (no content relevance, no value in summarizing the reference article)\n",
      "\n",
      "If you would like to provide another prompt or context, I'd be happy to assist with evaluating a generated summary!\n",
      "Evaluation explanation: To evaluate the generated summary, I will compare it with the reference summary. Here's my reasoning:\n",
      "\n",
      "* Content coverage: The generated summary mentions that you'll focus on extracting important points and condensing them into a clear and concise summary, but it doesn't provide any actual information about the financial news article. This means that the generated summary lacks content coverage.\n",
      "* Conciseness: The generated summary is very brief and does not convey any meaningful information about the topic.\n",
      "* Clarity: The language used in the generated summary is informal and unclear.\n",
      "\n",
      "Score: 0/1\n",
      "\n",
      "The score is 0 because the generated summary fails to provide any actual information about the financial news article, lacks content coverage, and is not concise or clear.\n",
      "Evaluation explanation: **Score: 0.25**\n",
      "\n",
      "The generated summary has a significant difference in content coverage compared to the reference summary. The generated summary is more focused on explaining the summarization process, while the reference summary provides detailed analysis of Apple's quarterly earnings report.\n",
      "\n",
      "Additionally, the generated summary does not mention any specific topic or article, whereas the reference summary discusses oil prices and recommendations for two Thai companies: PTT and PTTEP. This indicates a lack of conciseness and clarity in the generated summary.\n",
      "\n",
      "The only similarity between the two summaries is the use of phrases like \"I understand!\" and \"Let me know when you have an article...\", which are not relevant to the content of the reference summary.\n",
      "Evaluation explanation: The generated summary does not match the reference summary in terms of content coverage. The reference is a detailed financial news article about KIAT's winning bid for a 5-year LNG transportation contract with PTT, while the generated summary asks for a concise summary highlighting key takeaways.\n",
      "\n",
      "Since there is no actual generated summary provided (only the AI's understanding and a request to provide the financial news article), I will assume a score of 0. This reflects that there is no content comparison possible between the generated and reference summaries.\n",
      "Evaluation explanation: **Score:** 0.35 (very poor)\n",
      "\n",
      "The generated summary has almost no relation to the reference summary. It appears to be a response to an unrelated conversation about summarization, with phrases like \"I'll use those phrases to guide my summarization process\" and \"Just give me the article text, and I'll get to work!\". The generated text does not cover any of the key points from the reference summary, which discusses the challenges faced by startups in Thailand when it comes to securing funding.\n",
      "\n",
      "There is no content coverage, conciseness, or clarity in the generated summary. It seems to be a random collection of words and phrases that are unrelated to the topic at hand. The score reflects this lack of connection between the generated text and the reference summary.\n",
      "Evaluation explanation: **Score:** 0.2 (Poor)\n",
      "\n",
      "The generated summary does not address the content of the reference summary at all. It appears to be a generic statement about delivering concise summaries, unrelated to the specific article provided. The summary does not mention key points from the article, such as Chanel and Burberry issuing ESG bonds, or the increasing trend of ESG bond issuance in Thailand. This lack of content coverage is a major factor in the low score.\n",
      "\n",
      "The generated summary also fails to provide clarity on any aspect of the reference summary. It does not even attempt to summarize the main points or ideas from the article.\n",
      "Evaluation explanation: The generated summary is quite unrelated to the reference summary. The reference discusses a news article about oil prices increasing due to an attack by Houthi rebels in Yemen, and its potential impact on Thai energy stocks. In contrast, the generated summary talks about adding phrases to prompts to give AI systems clear direction.\n",
      "\n",
      "Score: 0/1\n",
      "\n",
      "The generated summary does not cover any content from the reference summary, making it a poor representation of the actual article. The factors of content coverage, conciseness, and clarity are all severely lacking in this generated summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  25%|██▌       | 1/4 [57:50<2:53:31, 3470.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 143\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    142\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSuper AI SS4\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLevel 3 - INTERN\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mJupyter Notebook\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLatest-Dataset-Model-Generate\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEdit-Prompt\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGemma2-final-output.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 143\u001b[0m     \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 135\u001b[0m, in \u001b[0;36mrun_optimization\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m    115\u001b[0m initial_human_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYour task is to summarize the key content from the given news article. Follow these guidelines:\u001b[39m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124m1. Summarize the content in Thai.\u001b[39m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124m2. Use \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m at the beginning of each paragraph to create indentation.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124mArticle to summarize:\u001b[39m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{text}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    134\u001b[0m df \u001b[38;5;241m=\u001b[39m read_csv_file(file_path)\n\u001b[1;32m--> 135\u001b[0m best_system_prompt, best_human_prompt, best_score \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_summarizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mollama_engine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_human_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest System Prompt:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_system_prompt)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Human Prompt:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_human_prompt)\n",
      "Cell \u001b[1;32mIn[15], line 72\u001b[0m, in \u001b[0;36moptimize_prompts\u001b[1;34m(llm_summarizer, ollama_engine, initial_system_prompt, initial_human_prompt, df, epochs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizing prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m         current_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_summarizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mollama_engine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m current_score \u001b[38;5;241m>\u001b[39m best_score:\n\u001b[0;32m     75\u001b[0m             best_score \u001b[38;5;241m=\u001b[39m current_score\n",
      "Cell \u001b[1;32mIn[15], line 56\u001b[0m, in \u001b[0;36mevaluate_prompts\u001b[1;34m(llm_summarizer, ollama_engine, system_prompt, human_prompt, df)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     55\u001b[0m     summary \u001b[38;5;241m=\u001b[39m summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_summary\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 56\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mollama_engine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreference_summary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores)\n",
      "Cell \u001b[1;32mIn[15], line 38\u001b[0m, in \u001b[0;36mevaluate_summary\u001b[1;34m(ollama_engine, generated_summary, reference_summary)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_summary\u001b[39m(ollama_engine, generated_summary, reference_summary):\n\u001b[0;32m     31\u001b[0m     eval_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Consider factors such as content coverage, conciseness, and clarity. Explain your reasoning briefly, then provide the score.\u001b[39m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124mGenerated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_summary\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124mReference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference_summary\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124mExplanation and Score:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 38\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mollama_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)?\u001b[39m\u001b[38;5;124m'\u001b[39m, response)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:179\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     emit_warning()\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py:1271\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[1;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1268\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1269\u001b[0m     )\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1271\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m   1281\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py:946\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    932\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    933\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m         )\n\u001b[0;32m    945\u001b[0m     ]\n\u001b[1;32m--> 946\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py:789\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    788\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    790\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py:776\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    768\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    773\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    775\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 776\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    780\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    784\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    785\u001b[0m         )\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    787\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\llms\\ollama.py:431\u001b[0m, in \u001b[0;36mOllama._generate\u001b[1;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m--> 431\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\llms\\ollama.py:348\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    346\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[0;32m    347\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_stream_response_to_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\llms\\ollama.py:193\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[1;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    187\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    192\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[0;32m    194\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[0;32m    195\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    196\u001b[0m         api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    198\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\utils.py:572\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[1;34m(iterator, r)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    571\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 572\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:1206\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1208\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:1125\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1125\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "from textgrad.engine import get_engine\n",
    "\n",
    "# Initialize models\n",
    "summary_model = \"gemma2:9b\"\n",
    "llm_summarizer = ChatOllama(model=summary_model, use_gpu=True)\n",
    "\n",
    "ollama_engine = Ollama(model=\"llama3.1:8b\")\n",
    "tg.set_backward_engine(ollama_engine, override=True)\n",
    "\n",
    "def summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, text):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "    \n",
    "    response = llm_summarizer.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def evaluate_summary(ollama_engine, generated_summary, reference_summary):\n",
    "    eval_prompt = f\"\"\"You are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Consider factors such as content coverage, conciseness, and clarity. Explain your reasoning briefly, then provide the score.\n",
    "\n",
    "Generated: {generated_summary}\n",
    "Reference: {reference_summary}\n",
    "\n",
    "Explanation and Score:\"\"\"\n",
    "    \n",
    "    response = ollama_engine(eval_prompt)\n",
    "    match = re.search(r'\\d+(\\.\\d+)?', response)\n",
    "    if match:\n",
    "        try:\n",
    "            score = float(match.group())\n",
    "            print(f\"Evaluation explanation: {response}\")\n",
    "            return score\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert to float: {match.group()}\")\n",
    "            return 0\n",
    "    else:\n",
    "        print(f\"Could not extract score from: {response}\")\n",
    "        return 0\n",
    "\n",
    "def evaluate_prompts(llm_summarizer, ollama_engine, system_prompt, human_prompt, df):\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        summary = summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row['generated_summary'])\n",
    "        score = evaluate_summary(ollama_engine, summary, row['reference_summary'])\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_prompts(llm_summarizer, ollama_engine, initial_system_prompt, initial_human_prompt, df, epochs):\n",
    "    system_prompt = Variable(initial_system_prompt, role_description=\"System prompt for summarization\")\n",
    "    human_prompt = Variable(initial_human_prompt, role_description=\"Human prompt for summarization\")\n",
    "    optimizer = TextualGradientDescent([system_prompt, human_prompt]) \n",
    "    \n",
    "    best_score = 0\n",
    "    best_system_prompt = initial_system_prompt\n",
    "    best_human_prompt = initial_human_prompt\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Optimizing prompts\"):\n",
    "        try:\n",
    "            current_score = evaluate_prompts(llm_summarizer, ollama_engine, system_prompt.value, human_prompt.value, df)\n",
    "        \n",
    "            if current_score > best_score:\n",
    "                best_score = current_score\n",
    "                best_system_prompt = system_prompt.value\n",
    "                best_human_prompt = human_prompt.value\n",
    "        \n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Current Score: {current_score:.4f} | Best Score: {best_score:.4f}\")\n",
    "            print(f\"Current System Prompt: {system_prompt.value[:100]}...\")\n",
    "            print(f\"Current Human Prompt: {human_prompt.value[:100]}...\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "            loss = 1 - current_score\n",
    "            loss_var = Variable(str(loss), role_description=\"Loss for optimization\")\n",
    "            loss_var.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Add some randomness to avoid local optima\n",
    "            if epoch % 5 == 0:\n",
    "                system_prompt.value += \" \" + ollama_engine(\"Generate a short, relevant phrase to add to a summarization system prompt.\")\n",
    "                human_prompt.value += \" \" + ollama_engine(\"Generate a short, relevant phrase to add to a summarization human prompt.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            print(f\"Current system prompt: {system_prompt.value}\")\n",
    "            print(f\"Current human prompt: {human_prompt.value}\")\n",
    "    \n",
    "    return best_system_prompt, best_human_prompt, best_score\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # เลือกเฉพาะคอลัมน์ที่ต้องการ\n",
    "    df = df[['sum_extractive', 'extractive']]\n",
    "    \n",
    "    # ตั้งชื่อคอลัมน์ใหม่เพื่อความชัดเจน\n",
    "    df.columns = ['generated_summary', 'reference_summary']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_optimization(file_path):\n",
    "    initial_system_prompt = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "    initial_human_prompt = \"\"\"Your task is to summarize the key content from the given news article. Follow these guidelines:\n",
    "    1. Summarize the content in Thai.\n",
    "    2. Use \\t at the beginning of each paragraph to create indentation.\n",
    "    3. DO NOT leave blank lines between paragraphs. All paragraphs must be continuous with no blank lines.\n",
    "    4. Focus on main points and important secondary points.\n",
    "    5. Provide explanations of the article’s key topics without going into too much detail.\n",
    "    6. Preserve all proper nouns such as names of people, companies, or organizations.\n",
    "    7. Use 2-3 key sentences from the original article for each point.\n",
    "    8. Maintain the original meaning and context.\n",
    "    9. Arrange the content in the same order as presented in the original article.\n",
    "    10. Reduce redundancy by combining similar points or information.\n",
    "    11. DO NOT include any examples in the summary.\n",
    "\n",
    "    IMPORTANT: \n",
    "    - DO NOT include any examples or case studies in the summary. Focus only on the main points and key information.\n",
    "\n",
    "    Article to summarize:\n",
    "    {text}\"\"\"\n",
    "    \n",
    "    df = read_csv_file(file_path)\n",
    "    best_system_prompt, best_human_prompt, best_score = optimize_prompts(llm_summarizer, ollama_engine, initial_system_prompt, initial_human_prompt, df, epochs=4)\n",
    "    \n",
    "    print(\"\\nBest System Prompt:\", best_system_prompt)\n",
    "    print(\"\\nBest Human Prompt:\", best_human_prompt)\n",
    "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r'F:\\AI\\Super AI SS4\\Level 3 - INTERN\\Jupyter Notebook\\Latest-Dataset-Model-Generate\\Edit-Prompt\\final\\Gemma2-final-output.csv'\n",
    "    run_optimization(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation explanation: To evaluate the quality of the generated summary, I will compare it with the reference summary. Here's my reasoning:\n",
      "\n",
      "**Content Coverage:** The generated summary covers some key points from the original text, such as the total fundraising in the Thai stock market, the strength of Thai listed companies during the COVID-19 pandemic, and the popularity of certain IPOs. However, it lacks details and specific examples compared to the reference summary.\n",
      "\n",
      "**Conciseness:** Both summaries are concise, but the generated summary is slightly more condensed and might miss important points. The reference summary provides a better balance between conciseness and content coverage.\n",
      "\n",
      "**Clarity:** The clarity of the generated summary is good, but it could be improved by adding transitional phrases or words to connect ideas.\n",
      "\n",
      "Considering these factors, I would give the generated summary a score of **0.65** out of 1. While it covers some essential points, it lacks depth and detail compared to the reference summary.\n",
      "Evaluation explanation: The generated summary is a good representation of the reference summary, but it's not perfect. Here's my evaluation:\n",
      "\n",
      "* Content coverage: 0.8 (The generated summary covers all the main points from the reference, but omits some details such as \"ตามกลยุทธ์ New S-Curve : Life Science\" and specific examples like \"เตียงเคลื่อนย้ายผู้ป่วย\" and \"สถานที่สามารถใช้ที่มีอยู่ วังจันทร์วัลเลย์\")\n",
      "* Concision: 0.7 (The generated summary is a bit too concise, missing some essential details that are present in the reference)\n",
      "* Clarity: 0.9 (The language used in the generated summary is clear and easy to understand, but there's room for improvement)\n",
      "\n",
      "Overall score: 0.8\n",
      "\n",
      "This score reflects the fact that the generated summary is a good representation of the reference, but could benefit from more details and clarity. With some adjustments, it could be even closer to perfection!\n",
      "Evaluation explanation: The generated summary and reference summary both cover similar topics, including Thailand's economic growth, EEC (Eastern Economic Corridor), tourism, and business developments. However, there are some differences in content coverage.\n",
      "\n",
      "The generated summary misses out on some important details mentioned in the reference summary, such as the support from Thai Chamber of Commerce for EEC, the need to help SMEs (Small and Medium-sized Enterprises), and the potential candidates for CEO position at Thai Airways.\n",
      "\n",
      "On the other hand, the generated summary includes some new information not present in the reference summary, such as the upcoming conference on tourism writing in Thailand.\n",
      "\n",
      "In terms of conciseness, the generated summary is shorter and more concise than the reference summary. However, it may have sacrificed some details to achieve this brevity.\n",
      "\n",
      "As for clarity, both summaries are written in a clear and straightforward style. However, the generated summary may be slightly less clear due to the missing context and details.\n",
      "\n",
      "Overall, I would give the generated summary a score of 0.6 out of 1. While it covers some of the key points, it misses out on important information and may lack clarity in some areas.\n",
      "Evaluation explanation: Here's a brief comparison between the generated summary and the reference summary:\n",
      "\n",
      "**Content Coverage:** The generated summary covers most of the key points mentioned in the reference summary, but misses some details such as the breakdown of revenue growth for different businesses.\n",
      "\n",
      "**Conciseness:** The generated summary is concise and to the point, but is slightly shorter than the reference summary.\n",
      "\n",
      "**Clarity:** The language used in the generated summary is clear and easy to understand, but could be improved by adding more context to some of the statements.\n",
      "\n",
      "Based on these factors, I would give the generated summary a score of **0.8 out of 1.0**. While it captures the main points of the reference summary, it lacks some details and clarity in certain areas.\n",
      "Evaluation explanation: The generated summary and the reference summary share similar content, but there are some differences in details and phrasing. Here's a brief comparison:\n",
      "\n",
      "* Content coverage: 0.8 (the generated summary covers all the main points, but misses some specific details mentioned in the reference summary)\n",
      "* Clarity: 0.9 (both summaries are easy to understand, but the generated one might be slightly more concise at the expense of some clarity)\n",
      "* Concision: 0.7 (the generated summary is shorter and to the point, but lacks some specific examples and context found in the reference summary)\n",
      "\n",
      "Overall Score: 0.8\n",
      "\n",
      "The score indicates that the generated summary provides a good overview of the topic, but could benefit from more detailed information and specific examples to make it more comprehensive and engaging.\n",
      "Evaluation explanation: **Comparison Summary:**\n",
      "\n",
      "The generated summary provides a clear overview of the new director-general's plans for the water authority, including his vision, goals, and initiatives. However, it misses some crucial details mentioned in the reference summary.\n",
      "\n",
      "**Key differences:**\n",
      "\n",
      "* The reference summary mentions that the new director-general has been working with the water authority for 32 years and has a clear understanding of its challenges.\n",
      "* The generated summary lacks specific details about the \"G้าวสู่ Digital MWA\" vision, such as creating digital services and supporting national strategies.\n",
      "* The reference summary provides more context about the 5-year investment plan (2560-2565) with a budget of 42,750 million baht.\n",
      "\n",
      "**Score: 0.8/1**\n",
      "\n",
      "The generated summary is well-structured and easy to follow, but it misses some essential details from the original article. While it captures the essence of the new director-general's plans, it could benefit from additional context and specific information about the vision, goals, and initiatives.\n",
      "Evaluation explanation: Here's the comparison between the generated summary and the reference summary:\n",
      "\n",
      "**Content Coverage:** The generated summary covers about 70% of the content present in the reference summary. It mentions the postponement of PTT's commercial LNG export plan, the reasons behind it (increase in global LNG prices and reduced demand due to COVID-19), and the company's target market for LNG exports. However, it lacks details about the \"Regional LNG HUB\" project and the specific challenges faced by PTT during its initial trial run.\n",
      "\n",
      "**Conciseness:** The generated summary is concise, but slightly shorter than the reference summary. It effectively conveys the main points in a brief manner, making it easy to understand for readers who are unfamiliar with the topic.\n",
      "\n",
      "**Clarity:** The generated summary is clear and free of ambiguity. The language used is straightforward, and the structure is logical, making it easy to follow.\n",
      "\n",
      "Considering these factors, I would assign a score of **0.8** (out of 1) to the generated summary. While it effectively conveys the main points, it lacks some essential details present in the reference summary, which prevents it from achieving perfection.\n",
      "Evaluation explanation: The generated summary is quite accurate, but it lacks some details found in the reference summary.\n",
      "\n",
      "Strengths:\n",
      "\n",
      "* The generated summary covers the main points of the reference summary, including the request for the government to allocate 10,000 rai of land around the Sricha Cha station, the development of TOD areas and a new city, and the need to unlock the potential of the area by increasing the supply of land.\n",
      "* The language is clear and concise.\n",
      "\n",
      "Weaknesses:\n",
      "\n",
      "* Some details are missing or condensed in the generated summary. For example, it does not mention that the government has yet to develop its land in the EEZ area for economic purposes, nor does it specify that the development of TOD areas and a new city will be used to support a high-speed train project connecting three airports.\n",
      "* The generated summary also lacks some nuance found in the reference summary. For example, it does not mention the importance of considering various approaches to urban development, such as lessons from other countries, or the potential for tourism development.\n",
      "\n",
      "Score: 0.8\n",
      "\n",
      "I would give this summary a score of 0.8 out of 1. While it covers the main points and is clear and concise, it lacks some details and nuance found in the reference summary. With a bit more expansion on key points and attention to detail, it could be closer to perfect.\n",
      "Evaluation explanation: After comparing the generated summary with the reference summary, I would give a score of 0.7 out of 1.\n",
      "\n",
      "The generated summary covers some key points such as the expected improvement in performance due to high electricity sales during the second quarter, recognition of profit from GLOW, and plans for increasing debt-to-equity ratio. However, it lacks some important details mentioned in the reference summary, such as the update on solar farm investment and battery production plan.\n",
      "\n",
      "Additionally, while the generated summary attempts to provide concise information, some sentences seem a bit disjointed or lack clarity compared to the well-structured reference summary.\n",
      "\n",
      "Overall, while the generated summary is decent, it could benefit from more precise and comprehensive coverage of key points, as well as clearer sentence structure.\n",
      "Evaluation explanation: Here's the comparison between the generated summary and the reference summary:\n",
      "\n",
      "**Content Coverage:** 0.8/1\n",
      "The generated summary covers most of the key points from the reference summary, but it lacks some details such as specific dates and numbers (e.g., \"9 เดือน\", \"1.7 ล้านบาร์เรลต่อวัน\"). However, the main ideas and conclusions are well-represented.\n",
      "\n",
      "**Conciseness:** 0.6/1\n",
      "The generated summary is a bit longer than necessary, with some sentences that could be condensed or omitted without losing important information. The reference summary is more concise and to the point.\n",
      "\n",
      "**Clarity:** 0.9/1\n",
      "The generated summary is well-written and easy to understand, but there are some minor issues with grammar and sentence structure (e.g., \"มองว่าจะต้องจับตาระดับผลการประชุมกลุ่มประเทศผู้ส่งออกน้ำมัน (โอเปก) และนอกโอเปก\" could be rephrased for better clarity).\n",
      "\n",
      "Overall Score: 0.8/1\n",
      "While the generated summary is not perfect, it captures the main points and conclusions of the reference summary reasonably well. With some minor tweaks to conciseness and clarity, it could be improved to achieve a score closer to 1.\n",
      "Evaluation explanation: The generated summary is a good representation of the original article, but it lacks some details present in the reference summary. Here's my evaluation:\n",
      "\n",
      "* Content coverage: 0.8/1 (the generated summary covers the main points, but omits some specific details, such as the exact dates and locations mentioned in the reference summary)\n",
      "* Conciseness: 0.9/1 (the generated summary is concise and to the point, but could be even more so with minor adjustments)\n",
      "* Clarity: 0.95/1 (the language used is clear and easy to understand, although some minor grammatical corrections would improve its clarity)\n",
      "\n",
      "Overall score: 0.87/1\n",
      "\n",
      "The generated summary effectively conveys the main points of the article, including KIAT's winning of a major gas transportation contract with PTT and their readiness for Thailand 4.0 and future energy alternatives. However, it lacks some specific details present in the reference summary, which might make it slightly less accurate or comprehensive.\n",
      "Evaluation explanation: The generated summary is 0.8 out of 1.\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* Content coverage: The generated summary covers the main points about the difficulty of raising funds for Thai startups, the low success rate (less than 10%), and the importance of finding partners. However, it omits some details from the reference summary, such as the specific numbers for investment amounts.\n",
      "* Conciseness: The generated summary is concise and to the point, but it could be more condensed without losing essential information.\n",
      "* Clarity: The language used in the generated summary is clear and easy to understand, although there are a few instances of awkward phrasing.\n",
      "\n",
      "The score is lower than perfect (1) due to some missing details and minor issues with conciseness and clarity.\n",
      "Evaluation explanation: **Score: 0.8**\n",
      "\n",
      "The generated summary is clear and concise, covering the main points of ESG bonds being used by various organizations, including companies like Chanel and Burberry, as well as government agencies in Thailand. However, I deduct some points for:\n",
      "\n",
      "* Lack of specific details on the projects funded by ESG bonds, which are present in the reference summary.\n",
      "* Some minor inaccuracies in dates and amounts mentioned (e.g., \"1 พันล้านดอลลาร์สหรัฐ\" vs. \"mูลค่า 1.3 พันล้านดอลลาร์สหรัฐ\" in the generated summary).\n",
      "* A slightly different tone and style compared to the reference summary.\n",
      "\n",
      "Overall, the generated summary provides a good overview of ESG bonds and their increasing popularity, but could benefit from more precise details and a closer match to the original content.\n",
      "Evaluation explanation: The generated summary covers the main points of the original article, including:\n",
      "\n",
      "* The Houthi rebels' attack on a Saudi Arabian oil facility, leading to a surge in crude oil prices.\n",
      "* Analysts' positive views on energy stocks, particularly PTTEP, PTTGC, and BANPU.\n",
      "* The potential impact on Thailand's oil prices.\n",
      "\n",
      "However, there are some discrepancies between the generated summary and the reference summary:\n",
      "\n",
      "* The generated summary does not mention that the attack was an attempt to hit Saudi Arabia's oil facility, but instead focuses on the subsequent price surge.\n",
      "* The reference summary provides more context and information from different analysts, such as PTG's president mentioning that the price surge is only a short-term phenomenon.\n",
      "\n",
      "Given these factors, I would score the generated summary a 0.8 out of 1. While it covers the main points of the article, it lacks some nuance and context provided in the reference summary.\n",
      "Evaluation explanation: **Score:** 0.8 (out of 1)\n",
      "\n",
      "The generated summary covers the main points of the reference summary, including:\n",
      "\n",
      "* ACAP's plan to issue its third bond in 2020\n",
      "* The bond details: not exceeding 500 million THB, 2-year tenure, and a 6% annual interest rate\n",
      "* Plans to expand their credit portfolio, aiming for 20 billion THB within 5 years (2020-2024)\n",
      "* Progress on registering Global Service Center Company Limited at the MAI\n",
      "\n",
      "However, there are some minor differences in wording and specific details. The generated summary does not mention:\n",
      "\n",
      "* The rating of ACAP by Tris Rating as BBB Stable\n",
      "* The plan to submit a filing for Global Service Center's listing on the MAI within 2021\n",
      "* The completion of a credit deal with PTT Group, worth 400 million THB\n",
      "\n",
      "Overall, the generated summary is clear and concise, but it misses some important details from the reference summary.\n",
      "Evaluation explanation: **Score:** 0.8/1\n",
      "\n",
      "The generated summary covers the main point of market volatility in Thailand, caused by concerns over COVID-19. However, it lacks details found in the reference summary, such as the specific dates of market fluctuations, the number of executives buying back shares, and the impact on the stock market index.\n",
      "\n",
      "On the other hand, the generated summary is concise and easy to read, making it a good representation of the content for a general audience. The language is also clear and understandable, which is an advantage over the reference summary that contains some technical terms and abbreviations.\n",
      "\n",
      "The score reflects the generated summary's ability to capture the essence of the market situation, but with some notable omissions compared to the more comprehensive reference summary.\n",
      "Evaluation explanation: The generated summary covers the main points of the reference summary, including:\n",
      "\n",
      "* The increase in plastic usage due to COVID-19 and the delivery food industry\n",
      "* PTT Global Chemical's (GC) commitment to reducing single-use plastic waste and promoting sustainable practices\n",
      "* GC's projects, such as \"ส่งพลาสติกกลับบ้าน\" (Send Plastic Back Home), \"อัพไซคลิงอัพสไตล์ลิ่ง\" (Upcycling Upstyling), and Loop Connecting, which aim to promote recycling, reduce plastic waste, and encourage sustainable practices\n",
      "\n",
      "However, the generated summary is slightly less detailed than the reference summary. It does not mention specific statistics, such as the 15% increase in food delivery boxes, or quotes from PTT Global Chemical's executives.\n",
      "\n",
      "Score: 0.8 (out of 1)\n",
      "\n",
      "The generated summary is clear and concise, but it misses some important details and context provided in the reference summary.\n",
      "Evaluation explanation: The generated summary covers some of the key points from the reference summary, but it lacks clarity and conciseness. The content is not entirely accurate, as it mentions that PTTEP is the sole importer of LNG (Liquefied Natural Gas), which contradicts the reference summary's statement about opening up the market to private companies.\n",
      "\n",
      "Some strengths of the generated summary include:\n",
      "\n",
      "* Coverage of the new plan to split the import ratio between short-term and long-term contracts\n",
      "* Mention of the need for a balanced gas supply with three criteria (price, stability, and competition)\n",
      "* Reference to the requirement for interested parties to obtain licenses from the Energy Regulatory Commission\n",
      "\n",
      "However, some weaknesses include:\n",
      "\n",
      "* Lack of clarity on the context of the new plan and its implications\n",
      "* Inaccuracy in stating that PTTEP is the sole importer of LNG\n",
      "* Overemphasis on details not mentioned in the reference summary (e.g., the companies involved)\n",
      "\n",
      "Score: 0.6 (out of 1)\n",
      "Evaluation explanation: The generated summary is somewhat lacking in content coverage compared to the reference summary. While it mentions PTT's efforts to mitigate the effects of drought, its involvement in water resource management, and plans to reduce reliance on Chinese gas imports, some important details are missing.\n",
      "\n",
      "Specifically:\n",
      "\n",
      "* The reference summary provides more context about PTT's preparations for drought, including reducing water usage and implementing measures with the government.\n",
      "* It also mentions specific locations where PTT is planning to develop water resources (เล่มฉบัง, มาบตาพุด, etc.).\n",
      "* The generated summary omits these details and focuses more on PTT's general preparedness.\n",
      "\n",
      "However, both summaries share similar clarity and conciseness in their presentation of information. The generated summary is well-structured and easy to follow.\n",
      "\n",
      "Score: 0.7/1\n",
      "\n",
      "This score reflects the generated summary's good structure and clarity but reduced content coverage compared to the reference summary.\n",
      "Evaluation explanation: The generated summary is a good representation of the reference summary. Here's why:\n",
      "\n",
      "* Content coverage: Both summaries cover the key points, including SCN's contract with PTT, their role as station operators and maintainers, and their expertise in NGV.\n",
      "* Conciseness: The generated summary is slightly longer than the reference, but it still conveys all the necessary information.\n",
      "* Clarity: Both summaries are written in clear and simple language, making them easy to understand.\n",
      "\n",
      "However, I would deduct a small point for minor factual discrepancies (e.g., \"SCN เป็นผู้นำในธุรกิจก๊าซธรรมชาติ\" vs. \"การลงนามครั้งนี้ เป็นอีกผลงานสะท้อนว่า SCN เป็นผู้นำธุรกิจก๊าซธรรมชาติ\") and stylistic differences.\n",
      "\n",
      "Score: 0.85\n",
      "Epoch 1/4 | Current Score: 8.0725 | Best Score: 8.0725\n",
      "Current System Prompt: You are an AI specialized in extractive summarization for economic news articles....\n",
      "Current Human Prompt: Your task is to summarize the key content from the given news article. Follow these guidelines:\n",
      "    ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  25%|██▌       | 1/4 [45:21<2:16:05, 2721.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation explanation: **Explanation**\n",
      "\n",
      "The generated summary is concise, but it does not accurately capture the essence of the reference article. The content coverage is limited to a few sentences about the market performance and new listings on the Thai stock exchange. However, there is no mention of the impact of COVID-19, the growth of online trading, or the specific companies mentioned in the reference article.\n",
      "\n",
      "The clarity of the generated summary is also a concern, as it does not provide enough context for the reader to understand the significance of the market figures and company listings. The tone is somewhat passive, with no clear conclusion or takeaways from the data presented.\n",
      "\n",
      "**Score: 0.2/1**\n",
      "\n",
      "This score reflects the significant gap between the generated summary and the reference article in terms of content coverage, conciseness, and clarity. While the generated summary provides some basic information about market trends and company listings, it falls short of providing a comprehensive and engaging summary that would allow readers to fully understand the significance of these developments.\n",
      "Evaluation explanation: **Score: 0.6**\n",
      "\n",
      "The generated summary is a response to the request for a summary, but it does not actually condense the content of the reference article into 2-3 key points as requested. Instead, it appears to be a brief introduction or question related to summarization.\n",
      "\n",
      "If we were to evaluate the generated summary as if it were intended to summarize the article, here's how I would score it:\n",
      "\n",
      "* Content coverage: 0 (The generated summary does not mention any of the specific topics discussed in the reference article, such as PTT's new business strategies or its entry into the healthcare industry.)\n",
      "* Conciseness: 1 (The generated summary is brief and to the point.)\n",
      "* Clarity: 0.5 (While the generated summary is clear, it does not provide any actual information about the content of the reference article.)\n",
      "\n",
      "Overall, without a summary to compare to, it's difficult to accurately assess the quality of the generated response in terms of summarization. However, if we were to assume that the task was simply to write a brief introduction or question related to summarization, then the score would be higher.\n",
      "Evaluation explanation: The generated summary correctly identifies the topics to be summarized, including investment, tourism, and business events. However, it does not capture the essence of each topic in detail.\n",
      "\n",
      "The reference summary covers a wide range of economic news articles, including:\n",
      "\n",
      "* Thailand's economy recovery\n",
      "* Investment and export growth\n",
      "* Tourism expansion\n",
      "* Business events such as SET Young Musician Competition and Thailand Local Tourism Design 2017\n",
      "* New developments in travel industry (e.g. unlimited travel passes for foreign tourists)\n",
      "\n",
      "The generated summary focuses on the instructions to condense the information into 2-3 key points, but it does not accurately capture the importance of each event or topic.\n",
      "\n",
      "Score: 0.6\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* Content coverage: The generated summary only captures a fraction of the topics covered in the reference summary.\n",
      "* Conciseness: The generated summary is concise, but at the expense of accuracy and completeness.\n",
      "* Clarity: The language used in the generated summary is clear, but it does not provide enough context or details to make sense of each topic.\n",
      "\n",
      "Improvement areas:\n",
      "\n",
      "* Provide more specific topics to summarize\n",
      "* Focus on key events and developments rather than general topics\n",
      "* Use more descriptive language to capture the essence of each event\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I compare it with the reference summary. Here's my analysis:\n",
      "\n",
      "The generated summary is concise and attempts to capture the main points of the original article. However, it lacks specificity and details compared to the reference summary.\n",
      "\n",
      "* Content coverage: 0.6/1 (the generated summary doesn't mention specific business areas like \"FSU business\", \"receiving and mixing ships\" or the investment in Big Sea Co.)\n",
      "* Clarity: 0.7/1 (the generated summary is somewhat unclear, as it's too vague)\n",
      "* Conciseness: 0.8/1 (the generated summary meets the length requirement of 2-3 key points)\n",
      "\n",
      "Overall score: 0.65/1\n",
      "\n",
      "The reference summary provides a more comprehensive and detailed overview of the article, covering various business areas, investment plans, and financial performance. The generated summary is lacking in this regard.\n",
      "Evaluation explanation: Here's my evaluation of the generated summary:\n",
      "\n",
      "The generated summary is brief and to the point, but it only covers a small portion of the key information from the reference article. It focuses on the collaboration between GPSC and 24 M Technologies, mentioning the benefits of using 24 M's battery technology, including low cost, high safety, environmental friendliness, and short production process.\n",
      "\n",
      "However, it misses out on crucial details such as the actual product (residential energy storage system), the role of Mr. Chavalit Tip Pavani in GPSC, and the S-Curves policy mentioned in the reference article. The generated summary also lacks clarity and conciseness, making it difficult to follow.\n",
      "\n",
      "Score: 0.4\n",
      "\n",
      "The score is low due to the incomplete coverage of key points, lack of clarity, and concision issues.\n",
      "Evaluation explanation: Here's the comparison between the generated summary and the reference summary:\n",
      "\n",
      "The generated summary does not mention any key points or findings from the article. It only asks for an economic news article to summarize, which is unrelated to the content of the reference summary.\n",
      "\n",
      "Score: 0/1 (The generated summary fails to provide a summary of the reference text, making it impossible to evaluate its quality.)\n",
      "\n",
      "Note that this score does not reflect on the quality of the generated summary itself, but rather on its relevance and purpose in relation to the reference summary.\n",
      "Evaluation explanation: **Score:** 0.7\n",
      "\n",
      "The generated summary is concise, but it lacks content coverage compared to the reference summary. The most important insights, such as PTT's plans to send out liquefied natural gas (LNG) commercially in Q2 2021, the impact of COVID-19 on LNG demand and prices, and Thailand's reduced LNG consumption, are not fully captured.\n",
      "\n",
      "The generated summary does focus on the key points, but it omits specific details like PTT's collaboration with the Energy Regulatory Commission, the cancellation of a project due to COVID-19, and the expected drop in LNG prices. The clarity is also not perfect, as some sentences seem disconnected or lack context.\n",
      "Evaluation explanation: **Generated Summary:** \n",
      "Please provide me with the economic news article you'd like me to summarize. I'll then condense it into 2-3 key points, focusing on the most important findings and insights. Just paste the article text here, and I'll get to work! \n",
      "\n",
      "**Reference Summary:** สมาคมอสังหาฯชลบุรีเชียร์รัฐเร่งจัดรูปที่ดินหมื่นไร่ รับการพัฒนาพื้นที่รอบสถานีไฮสปีดเทรนและเมืองใหม่ศรีราชา-ชลบุรี จับตาพื้นที่รัศมี 60 กม.จากสถานีศรีราชาได้อานิสงส์...\n",
      "\n",
      "**Comparison:**\n",
      "\n",
      "The generated summary does not attempt to summarize the article, instead asking for the article text as input. This is a critical error, and it cannot be considered a suitable summary.\n",
      "\n",
      "In terms of content coverage, conciseness, and clarity, I would rate this \"summary\" 0 out of 1.\n",
      "\n",
      "**Score:** 0\n",
      "Evaluation explanation: Here's the comparison:\n",
      "\n",
      "**Generated Summary**: I was asked to summarize an economic news article, but no article text was provided. The response simply asks for the article text.\n",
      "\n",
      "**Reference Summary**: Provides a detailed and informative summary of a specific economic news article from Thailand, discussing GPSC's performance in Q2/2021, plans for solar farm investment, battery production, and capital increase.\n",
      "\n",
      "**Comparison**:\n",
      "\n",
      "* **Content Coverage**: 0 (the generated summary does not cover any content related to the reference summary)\n",
      "* **Conciseness**: N/A (the generated summary is incomplete and doesn't provide a concise summary of anything)\n",
      "* **Clarity**: N/A (the generated summary lacks clarity as it doesn't make sense in the context of summarizing an article)\n",
      "\n",
      "**Score: 0/1**\n",
      "\n",
      "The generated summary does not match the reference summary, which is detailed, informative, and relevant to the original article. The generated response seems unrelated to the task at hand, making it impossible to score.\n",
      "Evaluation explanation: I will evaluate the generated summary against the reference summary.\n",
      "\n",
      "Generated Summary:\n",
      "\n",
      "The generated summary is incomplete. It only contains a request for an economic news article, without providing any content.\n",
      "\n",
      "Reference Summary:\n",
      "\n",
      "The reference summary provides three possible scenarios from the OPEC meeting, their implications on oil prices and stock market, and recommendations to buy PTT and PTTEP stocks with specific price targets.\n",
      "\n",
      "Comparison:\n",
      "The generated summary does not contain any information about the topics mentioned in the reference summary. It lacks content coverage, conciseness, and clarity.\n",
      "\n",
      "Score: 0/1\n",
      "Evaluation explanation: The generated summary is missing, but based on the instruction \"Key points only\" provided to condense the main findings into a concise summary of 100-150 words, I'll assume it was not generated.\n",
      "\n",
      "To evaluate the quality of the reference summary, here's my analysis:\n",
      "\n",
      "* Content coverage: The summary covers all key points mentioned in the original article. It provides a clear overview of KIAT's win in a gas transportation contract, their preparedness for energy transportation services, and their financial performance.\n",
      "* Conciseness: The summary is concise, covering the essential information within 100-150 words.\n",
      "* Clarity: The language used is straightforward and easy to understand.\n",
      "\n",
      "Given the above factors, I would give the reference summary a score of **0.9** (out of 1). It effectively conveys the key points from the original article while maintaining clarity and conciseness.\n",
      "Evaluation explanation: **Comparison Result**\n",
      "\n",
      "The generated summary is compared to the reference summary. Here's a brief explanation of my reasoning:\n",
      "\n",
      "* **Content coverage**: The generated summary covers some key points from the original text, but it fails to mention specific details about the challenges of reaching round B funding and the importance of partnership.\n",
      "* **Conciseness**: The generated summary is concise, as requested, but it could be more concise while still maintaining the essential information.\n",
      "* **Clarity**: The clarity of the generated summary is good, but it could be improved by using more precise language.\n",
      "\n",
      "**Score: 0.7**\n",
      "\n",
      "The score reflects a moderate evaluation of the generated summary. While it covers some important points, it lacks specific details and does not fully convey the nuances of the original text. With minor adjustments to conciseness and clarity, the score could improve.\n",
      "Evaluation explanation: Here's the evaluation of the generated summary against the reference summary:\n",
      "\n",
      "The generated summary is incomplete and lacks essential details. It does not mention key points such as Chanel and Burberry's sustainability-linked bond issuance, the specific projects they will fund, or the growing trend of ESG bond issuances in Thailand.\n",
      "\n",
      "However, it correctly identifies the main topic (ESG bonds) and provides a brief context. The summary also mentions that it will provide the article before summarizing it, which is not necessary as I can assume the article exists.\n",
      "\n",
      "Content coverage: 0.2/1 (only partially addresses the topic)\n",
      "Conciseness: 0.3/1 (tries to summarize but lacks essential details)\n",
      "Clarity: 0.5/1 (clearly written but incomplete)\n",
      "\n",
      "Overall score: 0.4/1\n",
      "\n",
      "Please provide the economic news article as requested, and I will generate a summary that attempts to cover all key points and meets the desired standards.\n",
      "Evaluation explanation: **Content Coverage: 0.7**\n",
      "The generated summary focuses on the price increase of crude oil, but it doesn't cover all aspects mentioned in the reference article, such as the impact on Thai energy stocks, companies like PTTEP and PTT, and the response from authorities.\n",
      "\n",
      "**Conciseness: 1.0**\n",
      "The generated summary is concise, condensing the essential information into a few key points.\n",
      "\n",
      "**Clarity: 0.8**\n",
      "While the language used is clear, there are some nuances missing in the generated summary, such as the specific impact on Thai energy companies and the authorities' response to potential effects on global oil prices.\n",
      "\n",
      "Overall score: **0.8 (80%)**\n",
      "\n",
      "The generated summary provides a good overview of the article's main points but could benefit from further refinement to better capture the complexities and nuances presented in the reference text.\n",
      "Evaluation explanation: Here's the evaluation of the generated summary compared to the reference summary:\n",
      "\n",
      "The generated summary is too short and lacks specific information from the original article. The response \"Please provide me with the economic news article you'd like me to summarize...\" does not even attempt to condense the content, whereas a proper summary should aim to capture the essential points of the article.\n",
      "\n",
      "In contrast, the reference summary provides detailed key points about the company's plans for issuing new debt, its financial status, and future growth targets. It also mentions recent developments such as acquiring Global Service Center and the rating from Tris Rating.\n",
      "\n",
      "Given this comparison, I would assign a score of 0 out of 1, indicating that the generated summary does not meet the standards of providing an accurate and informative summary of the article.\n",
      "Evaluation explanation: The generated summary scores 0.42 out of 1.\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* Content coverage (0.6/1): The generated summary only mentions the stock market's performance, but omits other important points from the reference summary, such as the impact of COVID-19 on the market and the shutdown of the stock exchange.\n",
      "* Conciseness (0.8/1): The generated summary is concise, meeting the 100-150 word limit and focusing on key points.\n",
      "* Clarity (0.5/1): The generated summary's clarity is compromised by its incomplete content coverage and lack of specific details. It does not clearly convey the severity of the market downturn or the significance of corporate executives buying stocks.\n",
      "\n",
      "To improve, the generated summary should have expanded to cover more essential points from the reference summary and provided a clearer context for the key points presented.\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I compare it with the reference summary. Here's my analysis:\n",
      "\n",
      "**Content Coverage:** The generated summary barely covers any key points from the article, while the reference summary delves into several important aspects, including the increase in plastic usage during COVID-19, PTT Global Chemical's efforts to reduce single-use plastics, and their initiatives for waste management and recycling.\n",
      "\n",
      "**Conciseness:** The generated summary is too brief, lacking essential details, whereas the reference summary provides a more comprehensive overview of the topic within the 100-150 word limit.\n",
      "\n",
      "**Clarity:** The language used in the generated summary is ambiguous, making it difficult to understand the context. In contrast, the reference summary employs clear and concise language that effectively conveys the main points.\n",
      "\n",
      "Given these observations, I would assign a score of **0.25** (out of 1) for the generated summary. This reflects its limited content coverage, lack of conciseness, and unclear writing style. The reference summary, on the other hand, scores **0.95**, demonstrating an excellent balance between brevity and comprehensiveness.\n",
      "Evaluation explanation: I'll evaluate the generated summary against the reference summary.\n",
      "\n",
      "The generated summary is a simple question asking for an economic news article, while the reference summary is a long paragraph discussing the opening of natural gas business in Thailand. The content coverage between the two summaries is quite different.\n",
      "\n",
      "In terms of conciseness, the generated summary is extremely brief and lacks any substance, whereas the reference summary provides detailed information about the topic.\n",
      "\n",
      "Clarity-wise, the generated summary is unclear as it's asking for a specific article without providing any context or hints about what kind of news article would be suitable. The reference summary, on the other hand, explains the topic clearly and concisely.\n",
      "\n",
      "Considering these factors, I would give the generated summary a score of 0.2 out of 1. It lacks content coverage, is not concise, and unclear in its request.\n",
      "Evaluation explanation: Here's my evaluation:\n",
      "\n",
      "**Score:** 0.6/1\n",
      "\n",
      "The generated summary is a good start, but it lacks key details and clarity compared to the reference summary. Here's why:\n",
      "\n",
      "* **Content coverage**: The generated summary only mentions the current economic situation in Thailand, water shortages, and PTT's plans for PPP projects. It misses important points like PTT's strategy to reduce dependence on Chinese markets, their discussions with gas producers, and the potential impact on the country's resource management.\n",
      "* **Conciseness**: While the generated summary is concise, it fails to provide a clear and comprehensive overview of the main points. The reference summary provides a more balanced view of PTT's plans and strategies.\n",
      "* **Clarity**: The language used in the generated summary is straightforward, but it could be improved for better understanding.\n",
      "\n",
      "To reach a perfect score (1), the generated summary should cover all the essential points from the reference summary, provide a clear and concise overview, and use more precise language.\n",
      "Evaluation explanation: To evaluate the generated summary, I'll compare it to the reference summary.\n",
      "\n",
      "The generated summary is a request for an economic news article, asking the summarizer to provide 2-3 key points. This summary is not actually condensing any content, but rather making a request. Therefore, it doesn't have any content coverage or clarity in relation to the reference summary.\n",
      "\n",
      "In contrast, the reference summary provides detailed information about SCN's contract with PTT and its significance in the gas industry.\n",
      "\n",
      "Given this comparison, I would score the generated summary 0 out of 1, as it doesn't meet the requirements for a summary. It's more like a request or instruction, rather than an actual condensed version of content.\n",
      "Epoch 2/4 | Current Score: 109.4860 | Best Score: 109.4860\n",
      "Current System Prompt: You are an AI model designed to distill key points from economic news articles and present them in a...\n",
      "Current Human Prompt: Please condense the main points from the article into a concise summary (approx. 100-150 words), hig...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  50%|█████     | 2/4 [58:29<52:48, 1584.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation explanation: Here's my evaluation of the generated summary:\n",
      "\n",
      "The generated summary starts with a question asking for an article to be provided, which is not present in the reference summary. This indicates that the AI has not correctly understood its task or is missing crucial information.\n",
      "\n",
      "However, if we ignore this initial part and only consider the second half of the generated summary, it appears to cover some key points from the reference summary, such as:\n",
      "\n",
      "* The total funding raised by companies listed on the Thai stock exchange\n",
      "* The impact of COVID-19 on companies and the subsequent increase in IPOs\n",
      "* Examples of successful IPOs, including Central Retail Corporation, Srichita Golf, SCG Packaging, and PTT\n",
      "\n",
      "However, there are some significant differences between the generated summary and the reference summary:\n",
      "\n",
      "* The content coverage is not comprehensive, as it only mentions a few examples of successful IPOs without providing a broader context or more detailed information.\n",
      "* The conciseness of the generated summary is lacking, as it contains unnecessary words and phrases that make it less concise than the reference summary.\n",
      "* The clarity of the generated summary could be improved, as some sentences are not well-structured or easy to understand.\n",
      "\n",
      "Overall, I would give the generated summary a score of 0.3 out of 1. It shows some promise in covering key points from the reference summary but falls short in terms of content coverage, conciseness, and clarity.\n",
      "Evaluation explanation: **Generated Summary:** \n",
      "Please provide me with the article you would like me to summarize. I'm ready to analyze it and deliver a concise summary for you!\n",
      "\n",
      "**Reference Summary:** ปตท. หรือ PTT พยายามสู่ New S-Curve มุ่งธุรกิจนอนออยล์มากขึ้น ชัดจากกรณีรุกธุรกิจค้าปลีกผ่าน ปตท.น้ำมันและการค้าปลีก  หรือ OR จนสำเร็จมีสาขาทั่วประเทศ ปั๊มรายได้และกำไรให้กับ PTT ล่าสุดเตรียมเข้าตลาดหลักทรัพย์ฯ ปีหน้า หรือกรณีร้านคาเฟ่ อเมซอน ก็พิสูจน์ว่าทำได้ จากกาแฟในปั๊ม สู่ห้าง และขยายไปต่างประเทศ จนวันนี้ไม่เป็นรองใคร สู้แบรนด์นอกได้ โควิดทำให้เทรนด์สุขภาพมาแรง กับกำลังเข้าสู่สังคมผู้สูงอายุ PTT เริ่มรุกธุรกิจสุขภาพ จับมือกับองค์การเภสัชกรรม (อภ.) สร้างโรงงานผลิตยารักษามะเร็งแห่งแรกในไทย ล่าสุดตั้ง อินโนบิก (เอเซีย)  ด้วยทุนจดทะเบียน 2,000 ล้านบาท รองรับธุรกิจทางการแพทย์  ตามกลยุทธ์ New S-Curve : Life Science และ PTT มีช่องทางค้าปลีกทั้งในและต่างประเทศ ใช้เป็นช่องทางระบายสินค้าได้ ในแบบของ B2B หรือ B2C \n",
      "\n",
      "**Score:** 0.23\n",
      "\n",
      "The generated summary lacks content coverage, conciseness, and clarity. It does not touch upon any of the key points mentioned in the reference summary, such as PTT's expansion into new S-Curves, its success with retail business, or its recent ventures into healthcare and life science. The tone is also overly casual and unprofessional compared to the formal, informative style of the reference summary. Overall, the generated summary fails to meet basic expectations for a summary.\n",
      "Evaluation explanation: **Comparison Result**\n",
      "\n",
      "The generated summary has a score of **0.3**.\n",
      "\n",
      "**Reasoning:**\n",
      "\n",
      "While the generated summary attempts to cover some key points from the original article, it fails to capture the main themes and details. Here's what's missing:\n",
      "\n",
      "1. **Content coverage**: The summary only touches on two or three minor topics (e.g., อีอีซี, ดีดีบินไทย, บริษัท คินเท็ตสึ เรลเวย์ฯ) without providing a clear understanding of the context.\n",
      "2. **Conciseness**: The generated summary is too brief and lacks coherence, making it difficult to follow.\n",
      "3. **Clarity**: Some sentences are awkwardly phrased or lack necessary details, leading to confusion.\n",
      "\n",
      "The reference summary, on the other hand, provides a concise yet comprehensive overview of various economic and tourism-related developments in Thailand, including key events, investment opportunities, and initiatives.\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "To improve the generated summary's score:\n",
      "\n",
      "1. **Improve content coverage**: Expand on the topics covered and provide more context.\n",
      "2. **Increase conciseness**: While keeping the summary concise, ensure it remains coherent and easy to follow.\n",
      "3. **Enhance clarity**: Refine sentence structure and add necessary details to avoid confusion.\n",
      "\n",
      "By addressing these areas, you can generate a more accurate and informative summary that better reflects the content of the original article.\n",
      "Evaluation explanation: Here's the comparison:\n",
      "\n",
      "**Content Coverage**: The generated summary covers some key points from the reference summary, such as the growth of PRM's revenue and profit, investment in new ships, and focus on FSU business. However, it misses important details like the specific plans for increasing fleet size, expansion into new markets, and investments in Big Sea Co.\n",
      "\n",
      "**Conciseness**: The generated summary is quite concise, but lacks clarity due to a lack of contextual understanding. It's more of an invitation to summarize than a actual attempt to provide a concise summary.\n",
      "\n",
      "**Clarity**: The generated summary lacks clarity as it doesn't provide any clear insights or main points from the reference summary.\n",
      "\n",
      "Overall Score: 0.2/1\n",
      "\n",
      "The score is quite low due to the lack of content coverage, conciseness, and clarity in the generated summary. A good summary should be able to capture the essence of the original article while providing a concise overview of the main points. In this case, the generated summary falls short in all these aspects.\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I'll compare it with the reference summary.\n",
      "\n",
      "The generated summary (\"Please provide me with the article you would like summarized!\") is not related to the reference summary. It seems to be a request for an article, whereas the reference summary provides actual information about a company and its battery technology.\n",
      "\n",
      "Considering this discrepancy, I wouldn't score the generated summary against the reference summary. However, if we consider the task of generating a 1-2 sentence summary based on the provided text (which is not done in this case), I would score it as:\n",
      "\n",
      "**0**\n",
      "\n",
      "The reason is that there's no attempt to summarize the content, and the response is unrelated to the task at hand.\n",
      "Evaluation explanation: Here's the evaluation:\n",
      "\n",
      "The generated summary is \"Please provide me with the article you would like me to summarize! I'm ready to analyze it and give you a concise 1-2 sentence summary. 😊\" which doesn't contain any information about the article or its content.\n",
      "\n",
      "In contrast, the reference summary provides detailed information about the article, including the context of an interview with a person who is being promoted as the new governor of the water and sewage authority in Bangkok, Thailand. The reference summary also summarizes several key points from the interview, such as the plans for digital transformation, investment projects, and service improvements.\n",
      "\n",
      "The generated summary has zero content coverage (0) since it doesn't provide any information about the article or its content. However, considering the factors of conciseness and clarity, I would rate the generated summary 0/1 (perfect score is not applicable in this case).\n",
      "\n",
      "Score: 0\n",
      "Evaluation explanation: The generated summary seems to be an inquiry from a summarizer, whereas the reference summary is a detailed article about PTT's plan to export liquefied natural gas (LNG) commercially starting Q2 2021.\n",
      "\n",
      "Upon evaluating the two summaries:\n",
      "\n",
      "* Content coverage: The generated summary covers none of the content from the reference summary. (0/1)\n",
      "* Conciseness: The generated summary is brief, but it lacks any meaningful information. (0/1)\n",
      "* Clarity: The language used in the generated summary is clear and concise, but it's not relevant to the topic. (0/1)\n",
      "\n",
      "Overall Score: 0\n",
      "Evaluation explanation: **Generated Summary**: Please provide me with the article you would like me to summarize. I'm ready to analyze it and generate a concise summary for you!\n",
      "\n",
      "**Reference Summary**: สมาคมอสังหาริมทรัพย์จังหวัดชลบุรี เผยว่า รัฐจะจัดรูปที่ดิน 1 หมื่นไร่ เพื่อพัฒนาพื้นที่รอบสถานีไฮสปีดเทรนและเมืองใหม่ศรีราชา-ชลบุรี ด้วยพื้นที่รัศมี 60 กม.จากสถานีศรีราชา\n",
      "\n",
      "**Comparison and Score**: The generated summary has a score of **0.4/1**.\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* Content Coverage: The generated summary only mentions the request for a summary, whereas the reference summary provides specific information about the land development project.\n",
      "* Conciseness: The generated summary is extremely concise, but at the cost of omitting any meaningful content.\n",
      "* Clarity: The language used in the generated summary is unclear and does not provide any context.\n",
      "\n",
      "The reference summary, on the other hand, is clear and concise, providing specific details about the land development project.\n",
      "Evaluation explanation: The generated summary does not contain any information about the article, whereas the reference summary provides a detailed overview of the article's content. The lack of content coverage is significant, resulting in a score of 0.\n",
      "\n",
      "However, if I were to generate a summary based on the provided text, here's what it would look like:\n",
      "\n",
      "Generated Summary: GPSC expects better performance in Q2/2022 due to higher sales from the Sriracha power plant. The company has 4 operating projects and full-year profit recognition for GLOW. Investment plans for solar farms and battery factories are underway.\n",
      "\n",
      "Explanation:\n",
      "My score is not 0 because I can generate a summary that somewhat covers the content of the article, albeit concisely and with minor inaccuracies. However, it lacks depth and detail compared to the reference summary. The generated summary correctly mentions GPSC's expected better performance, operating projects, and investment plans, but does not provide further context or explanation.\n",
      "\n",
      "Score: 0.6 (out of 1)\n",
      "Evaluation explanation: Here's the evaluation of the generated summary:\n",
      "\n",
      "The generated summary starts with a request for an article to be summarized, but it does not provide any actual content. This is a significant departure from the reference summary, which provides a detailed analysis of the OPEC meeting and its potential impact on Thai oil companies.\n",
      "\n",
      "Content coverage: 0/1 (the generated summary has no content)\n",
      "\n",
      "Conciseness: 0/1 (the generated summary is extremely concise, but only because it lacks any meaningful content)\n",
      "\n",
      "Clarity: N/A (the generated summary does not provide any clear information or insights)\n",
      "\n",
      "Overall score: 0/1 (perfect score would be 1, indicating a summary that accurately covers the content, is concise and clear. However, since this generated summary has no content, it scores 0.)\n",
      "\n",
      "The reference summary provides a detailed analysis of the OPEC meeting, its potential impact on Thai oil companies, and specific recommendations for PTT and PTTEP. It also highlights the potential upside for these companies based on expected growth in profits.\n",
      "Evaluation explanation: The generated summary and reference summary differ significantly in terms of content coverage. The reference summary provides detailed information about the company's winning bid for a 5-year contract to transport LNG, its plans for business growth, and financial data for the second quarter of 2017. In contrast, the generated summary is too brief and lacks specific details.\n",
      "\n",
      "The score I would give to the generated summary is 0.2 out of 1. The main issues with the generated summary are:\n",
      "\n",
      "* It lacks content coverage: The generated summary fails to provide any meaningful information about the article's topic.\n",
      "* It is not concise: A good summary should condense the original text into a shorter form while maintaining its key points. The generated summary is too brief and does not capture the essence of the article.\n",
      "* It lacks clarity: The generated summary appears to be an unrelated sentence, making it unclear what it refers to.\n",
      "\n",
      "To achieve a higher score, the generated summary would need to provide a clear and concise overview of the article's main points, including its content coverage.\n",
      "Evaluation explanation: The generated summary \"Please provide me with the article you would like me to summarize. I'm ready to analyze it and deliver a concise 1-2 sentence summary!\" does not contain any content related to the reference summary, which discusses the challenges faced by Thai startups in securing funding.\n",
      "\n",
      "This is an incomplete and unrelated response. The generated summary fails to address the main topic of the reference summary, which is the struggles of Thai startups in securing funding. As such, it cannot be considered a valid summary.\n",
      "\n",
      "Score: 0/1\n",
      "Evaluation explanation: Here's my evaluation of the generated summary:\n",
      "\n",
      "The generated summary is: \"Please provide me with the article you would like summarized! I'm ready to distill its key points into a concise and accurate 1-2 sentence summary.\"\n",
      "\n",
      "This summary does not relate to the content of the reference summary at all. It appears to be a generic response to a request for summarization.\n",
      "\n",
      "The reference summary, on the other hand, discusses various companies' issuance of ESG bonds (green bonds linked to sustainability) and their intended uses for sustainable projects.\n",
      "\n",
      "Comparing the two summaries, I would give the generated summary a score of 0 out of 1. The content is completely unrelated, lacks conciseness, and does not clarify anything about the topic at hand.\n",
      "Evaluation explanation: Here's a comparison of the generated summary with the reference summary:\n",
      "\n",
      "The generated summary is a simple request for an article, whereas the reference summary provides a detailed analysis of a specific event (the Yemen Houthi attack on Saudi oil facilities) and its potential impact on the Thai energy market. The generated summary fails to cover any relevant content from the original text.\n",
      "\n",
      "Score: 0/1\n",
      "\n",
      "Reasoning: The generated summary is completely unrelated to the topic of the reference summary, which makes it an inaccurate representation of the text. It lacks content coverage, conciseness, and clarity, making it a poor summary.\n",
      "Evaluation explanation: **Comparison**\n",
      "\n",
      "The generated summary does not address the content of the reference summary at all. The reference summary provides detailed information about a company's plan to issue a new bond, their credit rating, expansion plans, and financial performance.\n",
      "\n",
      "**Reasoning**\n",
      "\n",
      "The generated summary is incomplete, concise, and lacks clarity. It only contains a general statement asking for an article to summarize, without any actual content from the reference summary. The main points of interest in the reference summary, such as the company's bond issuance plan, credit rating, expansion plans, and financial performance, are completely ignored.\n",
      "\n",
      "**Score**: 0/1\n",
      "Evaluation explanation: Here's the comparison:\n",
      "\n",
      "**Content coverage:** The generated summary barely mentions the market situation, focusing solely on the AI's ability to analyze articles. This is a significant departure from the reference summary, which thoroughly describes the market situation and the actions of certain executives.\n",
      "\n",
      "**Conciseness:** While the generated summary is short, it doesn't provide any meaningful information about the article being summarized. The reference summary, on the other hand, concisely summarizes the key points while still providing some context.\n",
      "\n",
      "**Clarity:** Unfortunately, the generated summary lacks clarity and coherence. It reads like a nonsensical response rather than an actual summary of the article.\n",
      "\n",
      "Considering these factors, I would give the generated summary a score of **0.2**, indicating that it falls far short of being a good summary.\n",
      "Evaluation explanation: The generated summary does not accurately capture the essence of the article. Here's a brief explanation:\n",
      "\n",
      "* The content coverage is low, as it only mentions one aspect of the article (the relationship between COVID-19 and plastic usage) without providing any context or depth.\n",
      "* The conciseness is high, but at the expense of clarity. The generated summary is vague and does not provide enough information for a reader to understand its relevance.\n",
      "* The tone is also inconsistent with the original text.\n",
      "\n",
      "Score: 0.2\n",
      "\n",
      "The reference summary effectively conveys the main points of the article, including:\n",
      "\n",
      "* The relationship between COVID-19 and plastic usage\n",
      "* GC's efforts to reduce single-use plastics and promote bioplastics\n",
      "* The development of a platform called \"Loop Connecting\" to encourage recycling and waste management\n",
      "* The importance of collaboration among various stakeholders in reducing plastic waste\n",
      "\n",
      "The reference summary provides a clear and concise overview of the article, making it easier for readers to understand its key points.\n",
      "Evaluation explanation: Here's the evaluation:\n",
      "\n",
      "The generated summary is \"Please provide me with the article you would like summarized. I'm ready to analyze it and deliver a concise, 1-2 sentence summary!\" This is not a summary at all, but rather a request for an article.\n",
      "\n",
      "Comparing this with the reference summary, which discusses the opening of the gas market and the plans for LNG imports, I can see that the generated \"summary\" fails to capture even a single aspect of the original text. The content coverage is 0, as there is no summary provided.\n",
      "\n",
      "I will award a score of **0** based on this comparison.\n",
      "Evaluation explanation: Here's the evaluation of the generated summary compared to the reference summary:\n",
      "\n",
      "The generated summary asks for an article to be summarized, while the reference summary is a quoted statement from Mr. Chansharp Trinunchote, CEO of PTT Public Company Limited. The two summaries are fundamentally different in content and purpose.\n",
      "\n",
      "Score: 0 (this comparison doesn't make sense as they're not even related)\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I will compare it with the reference summary. Here's my analysis:\n",
      "\n",
      "The generated summary only contains a prompt asking for an article to be summarized, whereas the reference summary is a complete article about a company (SCN) signing a contract with PTT.\n",
      "\n",
      "Given that the generated summary does not contain any content relevant to the topic of the reference summary, I will score it as 0 out of 1. The summary lacks content coverage, conciseness, and clarity, making it an incomplete and inaccurate representation of the original article.\n",
      "Epoch 3/4 | Current Score: 2.6850 | Best Score: 109.4860\n",
      "Current System Prompt: You are an AI model designed to distill key points from a given text or information, using your adva...\n",
      "Current Human Prompt: Please condense the main points from the article into a concise summary, omitting supporting details...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts:  75%|███████▌  | 3/4 [1:11:50<20:26, 1226.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation explanation: Here's a comparison of the generated summary with the reference summary:\n",
      "\n",
      "**Generated Summary:** Not provided, as this is the starting point for summarization. 🤔\n",
      "\n",
      "The evaluation will be based on the quality of the response to \"Please provide me with the article you would like summarized!\" which does not contain any information.\n",
      "\n",
      "**Reference Summary:** A detailed report about market capitalization and stock offerings in Thailand during COVID-19, highlighting strong companies and impressive fundraising results.\n",
      "\n",
      "Given that there is no generated summary provided, I will provide a score based on the quality of the response to the prompt:\n",
      "\n",
      "**Score: 0** (No content coverage, conciseness, or clarity can be evaluated)\n",
      "\n",
      "Please provide the actual generated summary for further evaluation.\n",
      "Evaluation explanation: **Content Coverage:** 0.6 (The generated summary covers the main idea of PTT trying to shift towards a new business strategy, but it lacks specific details about the company's expansion into healthcare and life sciences.)\n",
      "\n",
      "**Conciseness:** 0.7 (The generated summary is concise, but it could be more concise by eliminating unnecessary words or phrases.)\n",
      "\n",
      "**Clarity:** 0.8 (The generated summary is clear in its main point, but it lacks clarity in explaining the specifics of PTT's new business strategy and how it differs from their traditional oil business.)\n",
      "\n",
      "**Overall Score:** 0.65\n",
      "\n",
      "The generated summary attempts to capture the essence of PTT's shift towards a new business strategy, but it falls short in providing specific details about their expansion into healthcare and life sciences. The clarity could be improved by breaking down complex ideas into simpler terms.\n",
      "Evaluation explanation: **Content Coverage:** 0.6\n",
      "The generated summary does not mention the main topic of economic recovery in Thailand, which is the key point of the reference article.\n",
      "\n",
      "**Conciseness:** 0.8\n",
      "The generated summary is concise but it only mentions one aspect of the reference article (the SET Young Musician competition), whereas the reference article has multiple topics discussed.\n",
      "\n",
      "**Clarity:** 0.9\n",
      "The generated summary is clear and easy to understand, although it does not accurately represent the content coverage of the reference article.\n",
      "\n",
      "Overall Score: **0.7**\n",
      "The generated summary partially covers some aspects of the reference article but lacks content coverage and conciseness. The clarity is good, though.\n",
      "Evaluation explanation: Here's the comparison:\n",
      "\n",
      "The generated summary is a request for an article to be summarized, while the reference summary provides actual content. This means the generated summary does not relate to the topic of the reference summary at all.\n",
      "\n",
      "Given that the generated summary is unrelated to the reference summary, I would give it a score of 0 out of 1. The reason is simple: the generated summary fails to capture any aspect of the reference summary's content, tone, or context.\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I'll compare it with the reference summary. Here's my reasoning:\n",
      "\n",
      "The generated summary is concise (1 sentence) but only partially covers the key points mentioned in the reference summary. It doesn't mention the specific benefits of the 24 M battery technology or the joint investment by GPSC and 24 M Technologies.\n",
      "\n",
      "Score: 0.5/1\n",
      "\n",
      "While the generated summary is clear and easy to read, it lacks content coverage and conciseness compared to an ideal summary. A good summary should provide a brief overview of the main points, which this one doesn't achieve.\n",
      "Evaluation explanation: Here's the evaluation of the generated summary:\n",
      "\n",
      "The generated summary is \"Please provide me with the article you would like me to summarize. I'm ready to condense its key points into a clear and concise 1-2 sentence summary! 😊\". This is not a summary at all, but rather a request for an article.\n",
      "\n",
      "Compared to the reference summary, this generated response lacks content coverage, conciseness, and clarity entirely.\n",
      "\n",
      "I would give this generated summary a score of **0** out of 1. It does not meet any of the criteria for a good summary.\n",
      "Evaluation explanation: To evaluate the generated summary, I'll compare it with the reference summary. Here's my reasoning:\n",
      "\n",
      "* Content coverage: The generated summary mentions that PTT expects to start commercial LNG exports in Q2 2021, which is correct. However, it does not mention any specific details about the projects or the impact of COVID-19 on demand.\n",
      "* Conciseness: The generated summary is concise, but it's a bit too short and doesn't provide enough context.\n",
      "* Clarity: The language used in the generated summary is clear, but it could be more precise.\n",
      "\n",
      "Score: 0.6 (out of 1)\n",
      "\n",
      "The score reflects that the generated summary is on the right track, but it misses some important details and could be more concise and clear.\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I'll compare it with the reference summary. Here's my analysis:\n",
      "\n",
      "**Content Coverage:** The generated summary is too broad and doesn't cover the specific details mentioned in the reference summary, such as the association's initiative to develop 1,000 rai of land around the high-speed train station, the collaboration with the EEC committee, or the importance of land management.\n",
      "\n",
      "**Conciseness:** The generated summary is concise but lacks the essential information and context provided in the reference summary. It focuses solely on requesting an article without any summary.\n",
      "\n",
      "**Clarity:** The generated summary lacks clarity as it doesn't provide a clear direction or topic to summarize.\n",
      "\n",
      "Given these factors, I would score the generated summary a **0.2**, indicating that it is not representative of the content and lacks essential details.\n",
      "Evaluation explanation: Here's the evaluation:\n",
      "\n",
      "The generated summary (\"Please provide me with the article you would like me to summarize!\") is completely unrelated to the content of the reference summary. It seems to be a standard response from a summarization tool when it's not provided with an article to summarize.\n",
      "\n",
      "In terms of factors such as content coverage, conciseness, and clarity, the generated summary scores 0 out of 1 because it doesn't attempt to summarize any part of the reference text.\n",
      "\n",
      "The reference summary itself is relatively clear and concise, providing some insight into the performance of GPSC in the second quarter of 2562. However, without a generated summary to compare with, I'll just provide the score for the generated summary, which is 0.\n",
      "Evaluation explanation: **Comparison with Reference Summary**\n",
      "\n",
      "The generated summary does not address the content of the reference summary. The generated summary is a question asking for an article to summarize, while the reference summary is a actual text that needs to be summarized.\n",
      "\n",
      "Since the generated summary is a question and not a summary, I will assign a score of **0**. There is no content coverage, conciseness, or clarity in this response.\n",
      "Evaluation explanation: **Comparison with Reference Summary**\n",
      "\n",
      "The generated summary does not mention the content of the article at all. It's a generic message asking for an article to summarize, which is unrelated to the reference summary.\n",
      "\n",
      "**Score: 0/1**\n",
      "\n",
      "The score is 0 because the generated summary does not cover any aspect of the reference summary, including content coverage, conciseness, and clarity.\n",
      "Evaluation explanation: **Score: 0.4**\n",
      "\n",
      "The generated summary is quite different from the reference summary, both in terms of content coverage and tone. The generated summary asks for an article to summarize, whereas the reference summary discusses a specific topic related to startups in Thailand.\n",
      "\n",
      "Assuming the generated summary was intended to discuss the same topic as the reference summary (despite its initial request), it still falls short in several areas:\n",
      "\n",
      "1. **Content coverage**: The generated summary does not mention any of the key points from the reference summary, such as the low success rate for Thai startups to raise funds beyond Series A or the challenges faced by successful startups when transitioning to new funding rounds.\n",
      "2. **Conciseness**: The generated summary is vague and lacks a clear direction, whereas the reference summary presents specific quotes and insights from industry experts.\n",
      "3. **Clarity**: The tone of the generated summary is unclear and seems to be asking for an article rather than discussing a topic.\n",
      "\n",
      "Given these issues, I would score the generated summary 0.4 out of 1.\n",
      "Evaluation explanation: Here's the comparison:\n",
      "\n",
      "**Content Coverage**: The generated summary is too broad and doesn't capture the specific details mentioned in the reference summary. It lacks depth and coverage of key points, such as the projects that Chanel and Burberry will use their ESG bonds for.\n",
      "\n",
      "**Conciseness**: While the generated summary is concise, it's a bit too short to effectively convey the main ideas. The reference summary provides more context and specific examples, making it clearer what the article is about.\n",
      "\n",
      "**Clarity**: The language used in the generated summary is clear, but it doesn't provide much insight or nuance. In contrast, the reference summary has a more informative tone, with specific details that make the topic more engaging.\n",
      "\n",
      "**Score: 0.45**\n",
      "\n",
      "The score reflects the fact that the generated summary is somewhat accurate but lacks depth and detail. While it's concise and clear, it doesn't convey the same level of understanding as the reference summary. Improving content coverage, conciseness, and clarity would be necessary to achieve a higher score.\n",
      "Evaluation explanation: Here's the evaluation of the generated summary:\n",
      "\n",
      "The generated summary, \"Please provide me with the article you would like me to summarize!\", is unrelated to the content of the reference summary. It appears to be a request for an article, rather than a completed summary.\n",
      "\n",
      "In terms of content coverage, conciseness, and clarity, the score would be 0 out of 1. The generated summary does not capture any aspect of the original text and lacks coherence.\n",
      "Evaluation explanation: To compare the generated summary with the reference summary, I will evaluate factors such as content coverage, conciseness, and clarity.\n",
      "\n",
      "**Content Coverage:** The generated summary only mentions that the article talks about a company preparing to issue a third loan offering, but it does not provide any information on the actual content of the article. In contrast, the reference summary provides detailed information on the loan offering, including its value, interest rate, and repayment schedule.\n",
      "\n",
      "**Conciseness:** The generated summary is quite concise, as it is only two sentences long. However, it lacks essential details that are present in the reference summary.\n",
      "\n",
      "**Clarity:** The language used in the generated summary is clear and easy to understand, but it does not provide any insight into the main points of the article.\n",
      "\n",
      "Given these factors, I would assign a score of **0.2** out of 1. This means that the generated summary only partially covers the content of the reference summary and lacks essential details, making it less informative than the original text.\n",
      "Evaluation explanation: The generated summary completely misses the point of the reference article, which is about the stock market situation in Thailand due to COVID-19 concerns. The generated summary asks for an article to summarize, whereas the reference article provides a specific analysis of the Thai stock market.\n",
      "\n",
      "Score: 0 (the generated summary has no relevance to the reference article's content)\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I'll compare it with the reference summary.\n",
      "\n",
      "The generated summary is a request for an article to summarize, while the reference summary is a long piece of text discussing the importance of plastic waste management. The content coverage of the generated summary is extremely low compared to the reference summary.\n",
      "\n",
      "I'd give the generated summary a score of 0 out of 1, as it doesn't provide any relevant information or insights about the topic. It's essentially a blank slate for summarization.\n",
      "Evaluation explanation: **Generated Summary:** \n",
      "No summary was generated by the AI. The prompt asks for a 1-2 sentence summary, but no text is provided to summarize.\n",
      "\n",
      "**Reference Summary:**\n",
      "The reference summary is about the plan to open up the liquefied natural gas (LNG) market in Thailand, with the goal of improving fairness and competition among players. A new allocation plan will be proposed, which includes a mix of short-term and long-term contracts to ensure stable supply and competitive prices.\n",
      "\n",
      "**Score: 0**\n",
      "Since no summary was generated by the AI, it's not possible to compare it with the reference summary or provide a score. The prompt should have been answered with an actual summary, but instead, it asks for an article without providing any context or text.\n",
      "Evaluation explanation: **Score: 0.7**\n",
      "\n",
      "The generated summary is clear and concise, but it only captures the last part of the reference summary's content. The main points mentioned in the original article, such as PTT's response to drought situation, proposal for a PPP project for water production from seawater, and plans to reduce reliance on Chinese market, are not covered.\n",
      "\n",
      "The generated summary mentions the potential opportunity for Thailand to produce goods that were previously imported from China, but this is only one aspect of the original article. The reference summary covers more ground, including PTT's strategies for coping with drought, negotiations with gas producers, and plans for LNG imports.\n",
      "\n",
      "Overall, while the generated summary is clear and concise, it falls short in terms of content coverage compared to the reference summary.\n",
      "Evaluation explanation: To evaluate the quality of the generated summary, I'll compare it with the reference summary. Here's my analysis:\n",
      "\n",
      "The generated summary is incomplete and doesn't cover the main content points of the reference summary. It starts by asking for an article to summarize, which is not relevant to the comparison. The generated text also lacks clarity and conciseness, as it appears to be a fragment rather than a complete thought.\n",
      "\n",
      "In contrast, the reference summary provides a clear and concise overview of the news article's content, covering key points such as the signing of a 2-year maintenance contract between SCN and PTT, SCN's leadership in the gas industry, and their expertise in operating and maintaining natural gas stations across Thailand.\n",
      "\n",
      "Score: 0.25/1\n",
      "\n",
      "This score reflects the significant gap between the quality of the generated summary and the reference summary. The generated summary lacks content coverage, conciseness, and clarity, while the reference summary provides a well-structured and informative summary of the news article's main points.\n",
      "Epoch 4/4 | Current Score: 2.4475 | Best Score: 109.4860\n",
      "Current System Prompt: You are an AI model designed to provide a concise summary of complex information within seconds, typ...\n",
      "Current Human Prompt: Please condense the main points from the article into a concise summary that captures the essential ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing prompts: 100%|██████████| 4/4 [1:25:11<00:00, 1277.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best System Prompt: You are an AI model designed to distill key points from economic news articles and present them in a concise manner. Here is a short and relevant phrase that you could add to a summarization system prompt:\n",
      "\n",
      "\"Condense into 2-3 key points\"\n",
      "\n",
      "This phrase provides context for the summarization task by specifying the desired output (a brief summary of 2-3 key points) and can help guide the AI model in generating an accurate and concise summary.\n",
      "\n",
      "Best Human Prompt: Please condense the main points from the article into a concise summary (approx. 100-150 words), highlighting key findings, arguments, or insights that capture the essence of the original text. Here is a short and relevant phrase that you can add to a summarization human prompt:\n",
      "\n",
      "\"Key points only.\"\n",
      "\n",
      "This phrase tells the AI to focus on extracting the most important information from the text being summarized, and to leave out details or supporting evidence unless they are crucial to understanding the main idea.\n",
      "\n",
      "Best Score: 109.4860\n",
      "\n",
      "Prompt History:\n",
      "Epoch 1:\n",
      "System Prompt: You are an AI specialized in extractive summarization for economic news articles.\n",
      "Human Prompt: Your task is to summarize the key content from the given news article. Follow these guidelines:\n",
      "    1. Summarize the content in Thai.\n",
      "    2. Use \t at the beginning of each paragraph to create indentation.\n",
      "    3. DO NOT leave blank lines between paragraphs. All paragraphs must be continuous with no blank lines.\n",
      "    4. Focus on main points and important secondary points.\n",
      "    5. Provide explanations of the article’s key topics without going into too much detail.\n",
      "    6. Preserve all proper nouns such as names of people, companies, or organizations.\n",
      "    7. Use 2-3 key sentences from the original article for each point.\n",
      "    8. Maintain the original meaning and context.\n",
      "    9. Arrange the content in the same order as presented in the original article.\n",
      "    10. Reduce redundancy by combining similar points or information.\n",
      "    11. DO NOT include any examples in the summary.\n",
      "\n",
      "    IMPORTANT: \n",
      "    - DO NOT include any examples or case studies in the summary. Focus only on the main points and key information.\n",
      "\n",
      "    Article to summarize:\n",
      "    {text}\n",
      "Score: 8.0725\n",
      "--------------------------------------------------\n",
      "Epoch 2:\n",
      "System Prompt: You are an AI model designed to distill key points from economic news articles and present them in a concise manner. Here is a short and relevant phrase that you could add to a summarization system prompt:\n",
      "\n",
      "\"Condense into 2-3 key points\"\n",
      "\n",
      "This phrase provides context for the summarization task by specifying the desired output (a brief summary of 2-3 key points) and can help guide the AI model in generating an accurate and concise summary.\n",
      "Human Prompt: Please condense the main points from the article into a concise summary (approx. 100-150 words), highlighting key findings, arguments, or insights that capture the essence of the original text. Here is a short and relevant phrase that you can add to a summarization human prompt:\n",
      "\n",
      "\"Key points only.\"\n",
      "\n",
      "This phrase tells the AI to focus on extracting the most important information from the text being summarized, and to leave out details or supporting evidence unless they are crucial to understanding the main idea.\n",
      "Score: 109.4860\n",
      "--------------------------------------------------\n",
      "Epoch 3:\n",
      "System Prompt: You are an AI model designed to distill key points from a given text or information, using your advanced algorithms and natural language processing capabilities to generate an accurate and concise summary within seconds, typically 1-2 sentences long.\n",
      "Human Prompt: Please condense the main points from the article into a concise summary, omitting supporting details unless they are essential to understanding the primary idea or concept.\n",
      "Score: 2.6850\n",
      "--------------------------------------------------\n",
      "Epoch 4:\n",
      "System Prompt: You are an AI model designed to provide a concise summary of complex information within seconds, typically 1-2 sentences long, highlighting key points in a clear and accurate manner.\n",
      "Human Prompt: Please condense the main points from the article into a concise summary that captures the essential information, focusing on key findings, conclusions, or takeaways that are crucial to understanding the primary idea or concept.\n",
      "Score: 2.4475\n",
      "--------------------------------------------------\n",
      "[{'epoch': 1, 'system_prompt': 'You are an AI specialized in extractive summarization for economic news articles.', 'human_prompt': 'Your task is to summarize the key content from the given news article. Follow these guidelines:\\n    1. Summarize the content in Thai.\\n    2. Use \\t at the beginning of each paragraph to create indentation.\\n    3. DO NOT leave blank lines between paragraphs. All paragraphs must be continuous with no blank lines.\\n    4. Focus on main points and important secondary points.\\n    5. Provide explanations of the article’s key topics without going into too much detail.\\n    6. Preserve all proper nouns such as names of people, companies, or organizations.\\n    7. Use 2-3 key sentences from the original article for each point.\\n    8. Maintain the original meaning and context.\\n    9. Arrange the content in the same order as presented in the original article.\\n    10. Reduce redundancy by combining similar points or information.\\n    11. DO NOT include any examples in the summary.\\n\\n    IMPORTANT: \\n    - DO NOT include any examples or case studies in the summary. Focus only on the main points and key information.\\n\\n    Article to summarize:\\n    {text}', 'score': 8.0725}, {'epoch': 2, 'system_prompt': 'You are an AI model designed to distill key points from economic news articles and present them in a concise manner. Here is a short and relevant phrase that you could add to a summarization system prompt:\\n\\n\"Condense into 2-3 key points\"\\n\\nThis phrase provides context for the summarization task by specifying the desired output (a brief summary of 2-3 key points) and can help guide the AI model in generating an accurate and concise summary.', 'human_prompt': 'Please condense the main points from the article into a concise summary (approx. 100-150 words), highlighting key findings, arguments, or insights that capture the essence of the original text. Here is a short and relevant phrase that you can add to a summarization human prompt:\\n\\n\"Key points only.\"\\n\\nThis phrase tells the AI to focus on extracting the most important information from the text being summarized, and to leave out details or supporting evidence unless they are crucial to understanding the main idea.', 'score': 109.48599999999999}, {'epoch': 3, 'system_prompt': 'You are an AI model designed to distill key points from a given text or information, using your advanced algorithms and natural language processing capabilities to generate an accurate and concise summary within seconds, typically 1-2 sentences long.', 'human_prompt': 'Please condense the main points from the article into a concise summary, omitting supporting details unless they are essential to understanding the primary idea or concept.', 'score': 2.685}, {'epoch': 4, 'system_prompt': 'You are an AI model designed to provide a concise summary of complex information within seconds, typically 1-2 sentences long, highlighting key points in a clear and accurate manner.', 'human_prompt': 'Please condense the main points from the article into a concise summary that captures the essential information, focusing on key findings, conclusions, or takeaways that are crucial to understanding the primary idea or concept.', 'score': 2.4475000000000002}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "from textgrad.engine import get_engine\n",
    "\n",
    "# Initialize models\n",
    "summary_model = \"gemma2:9b\"\n",
    "llm_summarizer = ChatOllama(model=summary_model, use_gpu=True)\n",
    "\n",
    "ollama_engine = Ollama(model=\"llama3.1:8b\")\n",
    "tg.set_backward_engine(ollama_engine, override=True)\n",
    "\n",
    "def summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, text):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    messages = chat_prompt.format_messages(text=text)\n",
    "    \n",
    "    response = llm_summarizer.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def evaluate_summary(ollama_engine, generated_summary, reference_summary):\n",
    "    eval_prompt = f\"\"\"You are an AI that evaluates the quality of summaries. Compare the generated summary with the reference summary and provide a score between 0 and 1, where 1 is perfect. Consider factors such as content coverage, conciseness, and clarity. Explain your reasoning briefly, then provide the score.\n",
    "\n",
    "Generated: {generated_summary}\n",
    "Reference: {reference_summary}\n",
    "\n",
    "Explanation and Score:\"\"\"\n",
    "    \n",
    "    response = ollama_engine(eval_prompt)\n",
    "    match = re.search(r'\\d+(\\.\\d+)?', response)\n",
    "    if match:\n",
    "        try:\n",
    "            score = float(match.group())\n",
    "            print(f\"Evaluation explanation: {response}\")\n",
    "            return score\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert to float: {match.group()}\")\n",
    "            return 0\n",
    "    else:\n",
    "        print(f\"Could not extract score from: {response}\")\n",
    "        return 0\n",
    "\n",
    "def evaluate_prompts(llm_summarizer, ollama_engine, system_prompt, human_prompt, df):\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        summary = summarize_with_prompts(llm_summarizer, system_prompt, human_prompt, row['generated_summary'])\n",
    "        score = evaluate_summary(ollama_engine, summary, row['reference_summary'])\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_prompts(llm_summarizer, ollama_engine, initial_system_prompt, initial_human_prompt, df, epochs):\n",
    "    system_prompt = Variable(initial_system_prompt, role_description=\"System prompt for summarization\")\n",
    "    human_prompt = Variable(initial_human_prompt, role_description=\"Human prompt for summarization\")\n",
    "    optimizer = TextualGradientDescent([system_prompt, human_prompt]) \n",
    "    \n",
    "    best_score = 0\n",
    "    best_system_prompt = initial_system_prompt\n",
    "    best_human_prompt = initial_human_prompt\n",
    "    \n",
    "    # Keep track of all prompts\n",
    "    prompt_history = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Optimizing prompts\"):\n",
    "        try:\n",
    "            current_score = evaluate_prompts(llm_summarizer, ollama_engine, system_prompt.value, human_prompt.value, df)\n",
    "        \n",
    "            # Save the prompts of the current epoch\n",
    "            prompt_history.append({\n",
    "                \"epoch\": epoch+1,\n",
    "                \"system_prompt\": system_prompt.value,\n",
    "                \"human_prompt\": human_prompt.value,\n",
    "                \"score\": current_score\n",
    "            })\n",
    "        \n",
    "            if current_score > best_score:\n",
    "                best_score = current_score\n",
    "                best_system_prompt = system_prompt.value\n",
    "                best_human_prompt = human_prompt.value\n",
    "        \n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Current Score: {current_score:.4f} | Best Score: {best_score:.4f}\")\n",
    "            print(f\"Current System Prompt: {system_prompt.value[:100]}...\")\n",
    "            print(f\"Current Human Prompt: {human_prompt.value[:100]}...\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "            loss = 1 - current_score\n",
    "            loss_var = Variable(str(loss), role_description=\"Loss for optimization\")\n",
    "            loss_var.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Add some randomness to avoid local optima\n",
    "            if epoch % 5 == 0:\n",
    "                system_prompt.value += \" \" + ollama_engine(\"Generate a short, relevant phrase to add to a summarization system prompt.\")\n",
    "                human_prompt.value += \" \" + ollama_engine(\"Generate a short, relevant phrase to add to a summarization human prompt.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            print(f\"Current system prompt: {system_prompt.value}\")\n",
    "            print(f\"Current human prompt: {human_prompt.value}\")\n",
    "    \n",
    "    return best_system_prompt, best_human_prompt, best_score, prompt_history\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # เลือกเฉพาะคอลัมน์ที่ต้องการ\n",
    "    df = df[['sum_extractive', 'extractive']]\n",
    "    \n",
    "    # ตั้งชื่อคอลัมน์ใหม่เพื่อความชัดเจน\n",
    "    df.columns = ['generated_summary', 'reference_summary']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_optimization(file_path):\n",
    "    initial_system_prompt = \"\"\"You are an AI specialized in extractive summarization for economic news articles.\"\"\"\n",
    "    initial_human_prompt = \"\"\"Your task is to summarize the key content from the given news article. Follow these guidelines:\n",
    "    1. Summarize the content in Thai.\n",
    "    2. Use \\t at the beginning of each paragraph to create indentation.\n",
    "    3. DO NOT leave blank lines between paragraphs. All paragraphs must be continuous with no blank lines.\n",
    "    4. Focus on main points and important secondary points.\n",
    "    5. Provide explanations of the article’s key topics without going into too much detail.\n",
    "    6. Preserve all proper nouns such as names of people, companies, or organizations.\n",
    "    7. Use 2-3 key sentences from the original article for each point.\n",
    "    8. Maintain the original meaning and context.\n",
    "    9. Arrange the content in the same order as presented in the original article.\n",
    "    10. Reduce redundancy by combining similar points or information.\n",
    "    11. DO NOT include any examples in the summary.\n",
    "\n",
    "    IMPORTANT: \n",
    "    - DO NOT include any examples or case studies in the summary. Focus only on the main points and key information.\n",
    "\n",
    "    Article to summarize:\n",
    "    {text}\"\"\"\n",
    "    \n",
    "    df = read_csv_file(file_path)\n",
    "    best_system_prompt, best_human_prompt, best_score, prompt_history = optimize_prompts(llm_summarizer, ollama_engine, initial_system_prompt, initial_human_prompt, df, epochs=4)\n",
    "    \n",
    "    print(\"\\nBest System Prompt:\", best_system_prompt)\n",
    "    print(\"\\nBest Human Prompt:\", best_human_prompt)\n",
    "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
    "    \n",
    "    # Print full prompt history\n",
    "    print(\"\\nPrompt History:\")\n",
    "    for entry in prompt_history:\n",
    "        print(f\"Epoch {entry['epoch']}:\")\n",
    "        print(f\"System Prompt: {entry['system_prompt']}\")\n",
    "        print(f\"Human Prompt: {entry['human_prompt']}\")\n",
    "        print(f\"Score: {entry['score']:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return prompt_history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r'F:\\AI\\Super AI SS4\\Level 3 - INTERN\\Jupyter Notebook\\Latest-Dataset-Model-Generate\\Edit-Prompt\\final\\Gemma2-final-output.csv'\n",
    "    optimize = run_optimization(file_path)\n",
    "    print(optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
